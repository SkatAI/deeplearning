{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gYhsn9ZcfoCN"
      },
      "source": [
        "# RNN - séries temporelles\n",
        "\n",
        "Dans ce notebook, nous allons construire des RNNs de prédiction de séries temporelles univariées. \n",
        "\n",
        "Un premier dataset est le prix d'ouverture de cotation de l'action Google.\n",
        "Nous implémentons 3 RNNs : simple, LSTM et GRU\n",
        "\n",
        "Votre mission :\n",
        "Modifier les architectures et paramètres des modeles pour estimer les performances, rapidité d'exécution et complexité des modèles.  \n",
        "N'hésitez pas à ajouter tensorboard pour analyser les modèles.\n",
        "Battre le score de `mean_absolute_error` de 1.78\n",
        "Dans un second temps, appliquez ces modèles sur un autre dataset comme celui des taches solaires\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RJ2t-4NzfjoM"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import yfinance as yf\n",
        "import datetime as dt\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "\n",
        "pd.set_option('display.max_columns',30)\n",
        "pd.set_option('display.max_rows',10)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z-ndKBcFgSh2"
      },
      "outputs": [],
      "source": [
        "#the start and end date\n",
        "start_date = dt.datetime(2020,4,1)\n",
        "end_date = dt.datetime(2023,4,1)\n",
        "\n",
        "#loading from yahoo finance\n",
        "data = yf.download(\"GOOGL\",start_date, end_date)\n",
        "\n",
        "print()\n",
        "print()\n",
        "\n",
        "print(data.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7hQPl1C1gUV3"
      },
      "outputs": [],
      "source": [
        "# Setting 80 percent data for training\n",
        "training_data_len = math.ceil(len(data) * .8)\n",
        "training_data_len\n",
        "\n",
        "#Splitting the dataset\n",
        "train_data = data[:training_data_len].iloc[:,:1]\n",
        "test_data = data[training_data_len:].iloc[:,:1]\n",
        "print(train_data.shape, test_data.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PaAGUrXmgYCP"
      },
      "outputs": [],
      "source": [
        "# Selecting Open Price values\n",
        "dataset_train = train_data.Open.values\n",
        "# Reshaping 1D to 2D array\n",
        "# dataset_train = np.reshape(dataset_train, (-1,1))\n",
        "# dataset_train.shape\n",
        "dataset_train[:2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AQnuscUemvl7"
      },
      "outputs": [],
      "source": [
        "dataset_train = np.reshape(dataset_train, (-1,1))\n",
        "dataset_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AsJf3IdmnFAE"
      },
      "outputs": [],
      "source": [
        "dataset_train[:2]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uJql1PiynEpt"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-ceWkbGbgblP"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler(feature_range=(0,1))\n",
        "# scaling dataset\n",
        "scaled_train = scaler.fit_transform(dataset_train)\n",
        "\n",
        "print(scaled_train[:5])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C3N7e46Kgd7l"
      },
      "outputs": [],
      "source": [
        "# Selecting Open Price values\n",
        "dataset_test = test_data.Open.values\n",
        "# Reshaping 1D to 2D array\n",
        "dataset_test = np.reshape(dataset_test, (-1,1))\n",
        "# Normalizing values between 0 and 1\n",
        "scaled_test = scaler.fit_transform(dataset_test)\n",
        "print(*scaled_test[:5])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "liE02_7Wggs9"
      },
      "outputs": [],
      "source": [
        "X_train = []\n",
        "y_train = []\n",
        "for i in range(50, len(scaled_train)):\n",
        "\tX_train.append(scaled_train[i-50:i, 0])\n",
        "\ty_train.append(scaled_train[i, 0])\n",
        "\tif i <= 51:\n",
        "\t\tprint(X_train)\n",
        "\t\tprint(y_train)\n",
        "\t\tprint()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5XJG33FXgle8"
      },
      "outputs": [],
      "source": [
        "X_test = []\n",
        "y_test = []\n",
        "for i in range(50, len(scaled_test)):\n",
        "\tX_test.append(scaled_test[i-50:i, 0])\n",
        "\ty_test.append(scaled_test[i, 0])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ujbtZwdggu22"
      },
      "source": [
        "In this step, the data is converted into a format that is suitable for input to an RNN. np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1)) transforms the X_train array, which was originally a 2-dimensional array of shape (samples, features), into a 3-dimensional array of shape (samples, time steps, features), where time steps denotes the number of time steps in the input sequence and features denotes the number of features in the input data. Size 1 is an additional dimension that serves as an indication that each time step only has a single feature.\n",
        "\n",
        "The y_train array is transformed from a 1-dimensional array of shape (samples) into a 2-dimensional array of shape (samples, 1) by np.reshape(y_train, (y_train.shape[0], 1)), where each row represents the output value at a certain time step."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PUyrOH5fgoo_"
      },
      "outputs": [],
      "source": [
        "# The data is converted to Numpy array\n",
        "X_train, y_train = np.array(X_train), np.array(y_train)\n",
        "\n",
        "#Reshaping\n",
        "X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1],1))\n",
        "y_train = np.reshape(y_train, (y_train.shape[0],1))\n",
        "print(\"X_train :\",X_train.shape,\"y_train :\",y_train.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "roli_c4IgwjK"
      },
      "outputs": [],
      "source": [
        "# The data is converted to numpy array\n",
        "X_test, y_test = np.array(X_test), np.array(y_test)\n",
        "\n",
        "#Reshaping\n",
        "X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1],1))\n",
        "y_test = np.reshape(y_test, (y_test.shape[0],1))\n",
        "print(\"X_test :\",X_test.shape,\"y_test :\",y_test.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wsrZQFrdg1zz"
      },
      "source": [
        "# Modelisation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DxyYdQREgzKR"
      },
      "outputs": [],
      "source": [
        "# importing libraries\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Dense\n",
        "from keras.layers import SimpleRNN\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import GRU, Bidirectional\n",
        "from keras.optimizers import SGD\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import mean_squared_error\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9_u-1PldokwS"
      },
      "source": [
        "ce modele defini un architecture bien particuliere\n",
        "\n",
        "- RNN(50), Dropout, 3 RNN(50) et Dense pour la sortie\n",
        "\n",
        "Que se passe t il si on change l'architecturer, si on la simplifie\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iopq-Otfg3xS"
      },
      "outputs": [],
      "source": [
        "# initializing the RNN\n",
        "regressor = Sequential()\n",
        "\n",
        "# adding RNN layers and dropout regularization\n",
        "regressor.add(SimpleRNN(units = 50,\n",
        "\t\t\t\t\t\tactivation = \"tanh\",\n",
        "\t\t\t\t\t\treturn_sequences = True,\n",
        "\t\t\t\t\t\tinput_shape = (X_train.shape[1],1)))\n",
        "\n",
        "regressor.add(Dropout(0.2))\n",
        "\n",
        "regressor.add(SimpleRNN(units = 50,\n",
        "\t\t\t\t\t\tactivation = \"tanh\",\n",
        "\t\t\t\t\t\treturn_sequences = True))\n",
        "\n",
        "regressor.add(SimpleRNN(units = 50,\n",
        "\t\t\t\t\t\tactivation = \"tanh\",\n",
        "\t\t\t\t\t\treturn_sequences = True))\n",
        "\n",
        "regressor.add( SimpleRNN(units = 50))\n",
        "\n",
        "# adding the output layer\n",
        "regressor.add(Dense(units = 1,activation='sigmoid'))\n",
        "\n",
        "# compiling RNN\n",
        "regressor.compile(optimizer = SGD(learning_rate=0.01,\n",
        "\t\t\t\t\t\t\t\tmomentum=0.9,\n",
        "\t\t\t\t\t\t\t\tnesterov=True),\n",
        "\t\t\t\tloss = \"mean_squared_error\")\n",
        "\n",
        "# fitting the model\n",
        "regressor.fit(X_train, y_train, epochs = 20, batch_size = 2)\n",
        "regressor.summary()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x2L5-YGIheWX"
      },
      "source": [
        "## Evaluation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x8TLOEW-g7We"
      },
      "outputs": [],
      "source": [
        "y_RNN = regressor.predict(X_test)\n",
        "y_RNN_O = scaler.inverse_transform(y_RNN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qW-ZsX8PwBRK"
      },
      "outputs": [],
      "source": [
        "y_RNN_O[:3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pNEJmv1GwPk5"
      },
      "outputs": [],
      "source": [
        "y_test_O = scaler.inverse_transform(y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "042Gb9IUwJfG"
      },
      "outputs": [],
      "source": [
        "y_test_O[:3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WFDFI6i1wVGJ"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "mean_absolute_error(y_test_O, y_RNN_O)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xn--ZQFnhnav"
      },
      "outputs": [],
      "source": [
        "fig, axs = plt.subplots(1,figsize =(12,6),sharex=True, sharey=True)\n",
        "fig.suptitle('Model Predictions')\n",
        "\n",
        "#Plot for RNN predictions\n",
        "plt.plot(train_data.index[150:], train_data.Open[150:], label = \"train_data\", color = \"b\")\n",
        "plt.plot(test_data.index, test_data.Open, label = \"test_data\", color = \"g\")\n",
        "plt.plot(test_data.index[50:], y_RNN_O, label = \"y_RNN\", color = \"black\")\n",
        "plt.grid()\n",
        "plt.legend()\n",
        "plt.title(\"Basic RNN\")\n",
        "\n",
        "\n",
        "plt.xlabel(\"Days\")\n",
        "plt.ylabel(\"Open price\")\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XDcxK4V-xfQD"
      },
      "source": [
        "# LSTM\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_P71alHyxeZY"
      },
      "outputs": [],
      "source": [
        "#Initialising the model\n",
        "regressorLSTM = Sequential()\n",
        "\n",
        "#Adding LSTM layers\n",
        "regressorLSTM.add(LSTM(50,\n",
        "\t\t\t\t\treturn_sequences = True,\n",
        "\t\t\t\t\tinput_shape = (X_train.shape[1],1)))\n",
        "regressorLSTM.add(LSTM(50,\n",
        "\t\t\t\t\treturn_sequences = False))\n",
        "regressorLSTM.add(Dense(25))\n",
        "\n",
        "#Adding the output layer\n",
        "regressorLSTM.add(Dense(1))\n",
        "\n",
        "#Compiling the model\n",
        "regressorLSTM.compile(optimizer = 'adam',\n",
        "\t\t\t\t\tloss = 'mean_squared_error'\n",
        "\t\t\t\t\t)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F54o5b4y0Trp"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mQLQUcu1wtjr"
      },
      "outputs": [],
      "source": [
        "#Fitting the model\n",
        "regressorLSTM.fit(X_train,\n",
        "\t\t\t\ty_train,\n",
        "\t\t\t\tbatch_size = 1,\n",
        "\t\t\t\tepochs = 12)\n",
        "regressorLSTM.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pYq5kE6Sx02t"
      },
      "outputs": [],
      "source": [
        "y_LSTM = regressorLSTM.predict(X_test)\n",
        "y_LSTM_O = scaler.inverse_transform(y_LSTM)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Be-2H-UEx8H0"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "mean_absolute_error(y_test_O, y_LSTM_O)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zdCkzmBZyH6A"
      },
      "outputs": [],
      "source": [
        "fig, axs = plt.subplots(1,figsize =(12,6),sharex=True, sharey=True)\n",
        "fig.suptitle('Model Predictions')\n",
        "\n",
        "#Plot for LSTM predictions\n",
        "plt.plot(train_data.index[150:], train_data.Open[150:], label = \"train_data\", color = \"b\")\n",
        "plt.plot(test_data.index, test_data.Open, label = \"test_data\", color = \"g\")\n",
        "plt.plot(test_data.index[50:], y_LSTM_O, label = \"y_LSTM\", color = \"black\")\n",
        "plt.grid()\n",
        "plt.legend()\n",
        "plt.title(\"LSTM\")\n",
        "\n",
        "\n",
        "plt.xlabel(\"Days\")\n",
        "plt.ylabel(\"Open price\")\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nTa7nnxTyRFi"
      },
      "source": [
        "# GRU\n",
        "\n",
        "Implementer le meme modele avec une couche GRU\n",
        "\n",
        "```\n",
        "regressorGRU = Sequential()\n",
        "\n",
        "# GRU layers with Dropout regularisation\n",
        "regressorGRU.add(GRU(units=50,\n",
        "                     return_sequences=True,\n",
        "                     input_shape=(X_train.shape[1],1),\n",
        "                     activation='tanh'))\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DcAJMKssyeM2"
      },
      "source": [
        "# resultats\n",
        "\n",
        " quelle methode est meilleure ?\n",
        "\n",
        " en terme de\n",
        " - rapidité ?\n",
        " - complexité ?\n",
        " - performance ?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bnCZQvU807gD"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ol3rFE6kmL5f"
      },
      "source": [
        "# sunspots\n",
        "\n",
        "Dataset alternatif\n",
        "\n",
        "url = https://raw.githubusercontent.com/SkatAI/skatai_deeplearning/master/data/sunspots.csv\n",
        "\n",
        "Etapes :\n",
        "\n",
        "- split train, test\n",
        "- reshape en [[]]\n",
        "- normaliser avec MinMaxScaler\n",
        "- construire les sequences\n",
        "\n",
        "```\n",
        "url = \"https://raw.githubusercontent.com/SkatAI/skatai_deeplearning/master/data/sunspots.csv\"\n",
        "\n",
        "spots = pd.read_csv(url)\n",
        "```\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
