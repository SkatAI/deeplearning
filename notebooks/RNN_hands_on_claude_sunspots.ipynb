{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Ouvrir sur Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/SkatAI/deeplearning/blob/master/notebooks/RNN_hands_on_claude_sunspots.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN et s√©ries temporelles ‚Äî Atelier pratique\n",
    "\n",
    "**Deep Learning par la pratique ‚Äî Alexis Perrier**\n",
    "\n",
    "---\n",
    "\n",
    "## Objectifs de cet atelier\n",
    "\n",
    "1. **Comprendre les RNN** : comment un r√©seau de neurones traite des donn√©es s√©quentielles\n",
    "2. **Pr√©dire une s√©rie temporelle** : les taches solaires (sunspots)\n",
    "3. **Comparer SimpleRNN, LSTM et GRU** : performance, vitesse, complexit√©\n",
    "4. **Travailler avec l'IA** : utiliser Gemini pour g√©n√©rer, lire et comprendre du code\n",
    "\n",
    "## Comment utiliser ce notebook\n",
    "\n",
    "- Les cellules avec du code pr√©-√©crit : **lisez, ex√©cutez, observez**\n",
    "- Les cellules marqu√©es ü§ñ **GEMINI** : demandez √† Gemini de g√©n√©rer le code, puis lisez-le et demandez-lui de vous l'expliquer\n",
    "- Les cellules marqu√©es ‚ùì **QUESTION** : r√©pondez en observant les r√©sultats\n",
    "\n",
    "**Utiliser l'IA pour coder n'est pas tricher ‚Äî c'est la m√©thode de travail.**\n",
    "Votre valeur n'est pas de taper du code, c'est de savoir quoi demander, comprendre ce qu'on vous donne, et juger si le r√©sultat est bon.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## √âtape 0 ‚Äî Setup et exploration des donn√©es\n",
    "\n",
    "On travaille avec le dataset **Sunspots** : le nombre mensuel de taches solaires observ√©es depuis 1749.\n",
    "Notre objectif : construire un mod√®le RNN qui pr√©dit le nombre de taches solaires √† partir des observations pass√©es.\n",
    "\n",
    "### 0.1 ‚Äî Imports"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import SimpleRNN, LSTM, GRU, Dense, Dropout\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import datetime, os\n",
    "\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"GPU disponible: {tf.config.list_physical_devices('GPU')}\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.2 ‚Äî Charger le dataset sunspots\n",
    "\n",
    "Le dataset contient le nombre mensuel de taches solaires depuis 1749. C'est une s√©rie temporelle classique en science des donn√©es, avec une p√©riodicit√© d'environ 11 ans (le cycle solaire)."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "url = \"https://raw.githubusercontent.com/SkatAI/deeplearning/master/data/sunspots.csv\"\n",
    "\n",
    "data = pd.read_csv(url)\n",
    "data.columns = ['n', 'date', 'number']\n",
    "data.index = data['date']\n",
    "\n",
    "print(f\"Nombre d'observations : {len(data)}\")\n",
    "print(f\"P√©riode : {data['date'].iloc[0]} ‚Üí {data['date'].iloc[-1]}\")\n",
    "print()\n",
    "data.head()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.3 ‚Äî Visualiser la s√©rie temporelle"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "plt.figure(figsize=(14, 5))\n",
    "plt.plot(data['number'], linewidth=0.8)\n",
    "plt.title('Taches solaires ‚Äî s√©rie compl√®te')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Nombre de taches solaires')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ü§ñ GEMINI ‚Äî Explorer les donn√©es\n",
    "\n",
    "Demandez √† Gemini :\n",
    "\n",
    "> *\"G√©n√®re du code pour afficher un zoom sur 100 points cons√©cutifs de la s√©rie `data['number']` (par exemple les indices 200 √† 300) et calcule des statistiques de base : moyenne, √©cart-type, min, max. Utilise matplotlib. Qu'observes-tu sur la p√©riodicit√© ?\"*\n",
    "\n",
    "Puis demandez :\n",
    "\n",
    "> *\"Explique-moi ce que tu observes. Y a-t-il un cycle visible ?\"*"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# VOTRE CODE G√âN√âR√â PAR GEMINI ICI\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚ùì QUESTION\n",
    "\n",
    "En observant la s√©rie temporelle :\n",
    "- La s√©rie est-elle r√©guli√®re ? Y a-t-il une p√©riodicit√© visible ?\n",
    "- Les pics ont-ils tous la m√™me amplitude ?\n",
    "- Un humain pourrait-il pr√©dire la suite de cette s√©rie ? Pourquoi ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*(vos observations ici)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## √âtape 1 ‚Äî Pr√©parer les donn√©es pour un RNN\n",
    "\n",
    "Un RNN ne prend pas un seul nombre en entr√©e : il prend une **s√©quence** de nombres. Pour pr√©dire le nombre de taches solaires au mois N, on lui donne les valeurs des mois N-50 √† N-1.\n",
    "\n",
    "C'est le principe de la **fen√™tre glissante** (sliding window).\n",
    "\n",
    "### 1.1 ‚Äî Split train/test (80/20)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# 80% pour l'entra√Ænement, 20% pour le test\n",
    "training_data_len = math.ceil(len(data) * 0.8)\n",
    "\n",
    "train_data = data[:training_data_len]['number']\n",
    "test_data = data[training_data_len:]['number']\n",
    "\n",
    "print(f\"Train : {len(train_data)} observations\")\n",
    "print(f\"Test  : {len(test_data)} observations\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 ‚Äî Normalisation avec MinMaxScaler\n",
    "\n",
    "Les RNN fonctionnent mieux avec des valeurs entre 0 et 1. On utilise `MinMaxScaler` pour normaliser les donn√©es."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Reshape en 2D pour le scaler\n",
    "dataset_train = train_data.values.reshape(-1, 1)\n",
    "dataset_test = test_data.values.reshape(-1, 1)\n",
    "\n",
    "# Normalisation\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled_train = scaler.fit_transform(dataset_train)\n",
    "\n",
    "# IMPORTANT : on utilise le m√™me scaler pour le test\n",
    "# (on ne fit pas un nouveau scaler sur le test !)\n",
    "scaler_test = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled_test = scaler_test.fit_transform(dataset_test)\n",
    "\n",
    "print(f\"Train ‚Äî min: {scaled_train.min():.2f}, max: {scaled_train.max():.2f}\")\n",
    "print(f\"Test  ‚Äî min: {scaled_test.min():.2f}, max: {scaled_test.max():.2f}\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 ‚Äî Cr√©er les fen√™tres glissantes\n",
    "\n",
    "On cr√©e des s√©quences de 50 pas de temps. Pour chaque fen√™tre de 50 valeurs, la cible est la valeur suivante (la 51√®me).\n",
    "\n",
    "```\n",
    "Fen√™tre 1 : [v0, v1, ..., v49]  ‚Üí  cible : v50\n",
    "Fen√™tre 2 : [v1, v2, ..., v50]  ‚Üí  cible : v51\n",
    "Fen√™tre 3 : [v2, v3, ..., v51]  ‚Üí  cible : v52\n",
    "...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "WINDOW_SIZE = 50\n",
    "\n",
    "def create_sequences(data, window_size):\n",
    "    \"\"\"Cr√©e les fen√™tres glissantes X et les cibles y.\"\"\"\n",
    "    X, y = [], []\n",
    "    for i in range(window_size, len(data)):\n",
    "        X.append(data[i - window_size:i, 0])\n",
    "        y.append(data[i, 0])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "X_train, y_train = create_sequences(scaled_train, WINDOW_SIZE)\n",
    "X_test, y_test = create_sequences(scaled_test, WINDOW_SIZE)\n",
    "\n",
    "print(f\"X_train : {X_train.shape}, y_train : {y_train.shape}\")\n",
    "print(f\"X_test  : {X_test.shape}, y_test  : {y_test.shape}\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 ‚Äî Reshape en tenseur 3D\n",
    "\n",
    "Un RNN attend des donn√©es au format **(n_samples, timesteps, features)** :\n",
    "- `n_samples` : nombre de fen√™tres\n",
    "- `timesteps` : taille de la fen√™tre (50)\n",
    "- `features` : nombre de variables par pas de temps (1, car s√©rie univari√©e)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Reshape pour le RNN : (samples, timesteps, features)\n",
    "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
    "y_train = y_train.reshape(y_train.shape[0], 1)\n",
    "\n",
    "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)\n",
    "y_test = y_test.reshape(y_test.shape[0], 1)\n",
    "\n",
    "print(f\"X_train : {X_train.shape}  ‚Üí  (samples, timesteps, features)\")\n",
    "print(f\"y_train : {y_train.shape}\")\n",
    "print(f\"X_test  : {X_test.shape}\")\n",
    "print(f\"y_test  : {y_test.shape}\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ü§ñ GEMINI ‚Äî Comprendre le format des donn√©es\n",
    "\n",
    "Demandez √† Gemini :\n",
    "\n",
    "> *\"Explique-moi pourquoi un RNN a besoin de donn√©es au format (n_samples, timesteps, features). Que repr√©sente chaque dimension ? Pourquoi utilise-t-on une fen√™tre glissante pour transformer une s√©rie temporelle en donn√©es d'entra√Ænement ?\"*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚ùì QUESTION\n",
    "\n",
    "- Combien d'√©chantillons d'entra√Ænement avons-nous ? Combien de test ?\n",
    "- Que se passerait-il si on augmentait la taille de la fen√™tre √† 100 ? Et si on la diminuait √† 10 ?\n",
    "- Pourquoi perd-on les 50 premi√®res observations ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*(vos r√©ponses ici)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Fonctions utilitaires\n",
    "\n",
    "On d√©finit deux fonctions qu'on r√©utilisera pour chaque mod√®le."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def plot_training(history, title):\n",
    "    \"\"\"Courbes de loss train/validation.\"\"\"\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.plot(history.history['loss'], label='Train', linewidth=2)\n",
    "    plt.plot(history.history['val_loss'], label='Validation', linewidth=2)\n",
    "    plt.title(f'{title} ‚Äî Loss (MSE)')\n",
    "    plt.xlabel('√âpoque')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_predictions(y_true, y_pred, title):\n",
    "    \"\"\"Plot pr√©dictions vs r√©alit√© sur le test set.\"\"\"\n",
    "    plt.figure(figsize=(14, 5))\n",
    "    plt.plot(y_true, label='R√©alit√©', linewidth=1.5)\n",
    "    plt.plot(y_pred, label='Pr√©dictions', linewidth=1.5, alpha=0.8)\n",
    "    plt.title(f'{title} ‚Äî Pr√©dictions vs R√©alit√©')\n",
    "    plt.xlabel('Observations (test set)')\n",
    "    plt.ylabel('Nombre de taches solaires (normalis√©)')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "print(\"Fonctions plot_training() et plot_predictions() d√©finies.\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## √âtape 2 ‚Äî Baseline : SimpleRNN\n",
    "\n",
    "On commence par le mod√®le le plus simple : un **SimpleRNN**. C'est un RNN classique o√π chaque neurone re√ßoit l'entr√©e courante et l'√©tat cach√© pr√©c√©dent.\n",
    "\n",
    "### 2.1 ‚Äî Construire le mod√®le SimpleRNN"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import time\n",
    "\n",
    "simple_rnn_model = Sequential([\n",
    "    SimpleRNN(50, activation='relu', input_shape=(WINDOW_SIZE, 1)),\n",
    "    Dense(1)\n",
    "])\n",
    "\n",
    "simple_rnn_model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "simple_rnn_model.summary()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ü§ñ GEMINI ‚Äî Comprendre l'architecture\n",
    "\n",
    "Demandez √† Gemini :\n",
    "\n",
    "> *\"Explique-moi le model.summary() du SimpleRNN ci-dessus. Combien de param√®tres a-t-il ? Comment un SimpleRNN traite-t-il une s√©quence pas √† pas ? Que signifie le chiffre 50 dans SimpleRNN(50) ?\"*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 ‚Äî Entra√Æner le SimpleRNN"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "print(\"Entra√Ænement du SimpleRNN...\")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "history_simple = simple_rnn_model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=20,\n",
    "    batch_size=32,\n",
    "    validation_data=(X_test, y_test),\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "time_simple = time.time() - start_time\n",
    "print(f\"\\nTemps d'entra√Ænement : {time_simple:.1f} secondes\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 ‚Äî Visualiser les r√©sultats"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Courbes de loss\n",
    "plot_training(history_simple, \"SimpleRNN\")\n",
    "\n",
    "# Pr√©dictions sur le test set\n",
    "y_pred_simple = simple_rnn_model.predict(X_test)\n",
    "\n",
    "plot_predictions(y_test, y_pred_simple, \"SimpleRNN\")\n",
    "\n",
    "# RMSE\n",
    "rmse_simple = np.sqrt(mean_squared_error(y_test.flatten(), y_pred_simple.flatten()))\n",
    "print(f\"RMSE SimpleRNN : {rmse_simple:.4f}\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚ùì QUESTION\n",
    "\n",
    "Observez les courbes et les pr√©dictions :\n",
    "- Le mod√®le capture-t-il la tendance g√©n√©rale de la s√©rie ?\n",
    "- Les pics (maxima) sont-ils bien pr√©dits ?\n",
    "- Y a-t-il de l'overfitting ? (la loss de validation remonte-t-elle ?)\n",
    "- Quelle est la RMSE ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*(vos observations ici)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## √âtape 3 ‚Äî LSTM\n",
    "\n",
    "### 3.1 ‚Äî Pourquoi LSTM ?\n",
    "\n",
    "Le **SimpleRNN** souffre du probl√®me du **vanishing gradient** : quand les s√©quences sont longues, le gradient devient tr√®s petit lors de la r√©tropropagation, et le mod√®le \"oublie\" les informations anciennes.\n",
    "\n",
    "Le **LSTM** (Long Short-Term Memory) r√©sout ce probl√®me gr√¢ce √† des **portes** (gates) qui contr√¥lent le flux d'information :\n",
    "- **Porte d'oubli** (forget gate) : quelles informations effacer de la m√©moire\n",
    "- **Porte d'entr√©e** (input gate) : quelles nouvelles informations stocker\n",
    "- **Porte de sortie** (output gate) : quelles informations transmettre\n",
    "\n",
    "R√©sultat : le LSTM peut m√©moriser des d√©pendances sur de longues s√©quences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ü§ñ GEMINI ‚Äî Construire le mod√®le LSTM\n",
    "\n",
    "Demandez √† Gemini :\n",
    "\n",
    "> *\"R√©√©cris le mod√®le SimpleRNN de l'√©tape 2 en rempla√ßant SimpleRNN par LSTM. Garde la m√™me structure : 1 couche LSTM(50), Dense(1), compile avec Adam et MSE. Entra√Æne pendant 20 epochs avec batch_size=32 et validation_data=(X_test, y_test). Mesure le temps d'entra√Ænement avec time.time(). Stocke le mod√®le dans `lstm_model`, l'historique dans `history_lstm` et le temps dans `time_lstm`.\"*\n",
    "\n",
    "Puis demandez :\n",
    "\n",
    "> *\"Combien de param√®tres a le LSTM par rapport au SimpleRNN ? Pourquoi cette diff√©rence ?\"*"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# VOTRE CODE G√âN√âR√â PAR GEMINI ICI\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 ‚Äî Visualiser les r√©sultats du LSTM"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Courbes de loss\n",
    "plot_training(history_lstm, \"LSTM\")\n",
    "\n",
    "# Pr√©dictions sur le test set\n",
    "y_pred_lstm = lstm_model.predict(X_test)\n",
    "\n",
    "plot_predictions(y_test, y_pred_lstm, \"LSTM\")\n",
    "\n",
    "# RMSE\n",
    "rmse_lstm = np.sqrt(mean_squared_error(y_test.flatten(), y_pred_lstm.flatten()))\n",
    "print(f\"RMSE LSTM : {rmse_lstm:.4f}\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚ùì QUESTION\n",
    "\n",
    "Comparez le LSTM avec le SimpleRNN :\n",
    "- Le LSTM fait-il mieux que le SimpleRNN ? Le RMSE a-t-il diminu√© ?\n",
    "- L'entra√Ænement est-il plus lent ? De combien ?\n",
    "- Les pr√©dictions sur les pics sont-elles meilleures ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*(vos observations ici)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## √âtape 4 ‚Äî Comparer les deux approches\n",
    "\n",
    "On met c√¥te √† c√¥te les r√©sultats du SimpleRNN et du LSTM."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Comparaison visuelle\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 5))\n",
    "\n",
    "# SimpleRNN\n",
    "axes[0].plot(y_test, label='R√©alit√©', linewidth=1.5)\n",
    "axes[0].plot(y_pred_simple, label='SimpleRNN', linewidth=1.5, alpha=0.8)\n",
    "axes[0].set_title(f'SimpleRNN ‚Äî RMSE: {rmse_simple:.4f}')\n",
    "axes[0].set_xlabel('Observations')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# LSTM\n",
    "axes[1].plot(y_test, label='R√©alit√©', linewidth=1.5)\n",
    "axes[1].plot(y_pred_lstm, label='LSTM', linewidth=1.5, alpha=0.8)\n",
    "axes[1].set_title(f'LSTM ‚Äî RMSE: {rmse_lstm:.4f}')\n",
    "axes[1].set_xlabel('Observations')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Tableau r√©capitulatif\n",
    "print(\"=\" * 60)\n",
    "print(\"COMPARAISON SimpleRNN vs LSTM\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"{'M√©trique':<30} {'SimpleRNN':>12} {'LSTM':>12}\")\n",
    "print(\"-\" * 60)\n",
    "print(f\"{'RMSE':<30} {rmse_simple:>12.4f} {rmse_lstm:>12.4f}\")\n",
    "print(f\"{'Param√®tres':<30} {simple_rnn_model.count_params():>12,} {lstm_model.count_params():>12,}\")\n",
    "print(f\"{'Temps entra√Ænement (s)':<30} {time_simple:>12.1f} {time_lstm:>12.1f}\")\n",
    "print(\"=\" * 60)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚ùì QUESTIONS\n",
    "\n",
    "Observez le tableau et les graphiques :\n",
    "\n",
    "1. **Lequel est meilleur** en termes de RMSE ?\n",
    "2. **Le gain de performance justifie-t-il** la complexit√© suppl√©mentaire (plus de param√®tres, entra√Ænement plus long) ?\n",
    "3. **√Ä partir de quelle epoch** les courbes de validation stagnent-elles pour chaque mod√®le ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*(vos r√©ponses ici)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## √âtape 5 ‚Äî Exp√©rimenter\n",
    "\n",
    "Maintenant c'est √† vous de jouer. Choisissez **une ou plusieurs** exp√©rimentations parmi les suivantes.\n",
    "\n",
    "Pour chaque exp√©rimentation :\n",
    "1. Demandez √† Gemini de g√©n√©rer le code\n",
    "2. Lisez le code et demandez √† Gemini de vous l'expliquer\n",
    "3. Ex√©cutez et observez les r√©sultats\n",
    "4. Notez vos conclusions\n",
    "\n",
    "---\n",
    "\n",
    "### Exp√©rimentation A ‚Äî GRU\n",
    "\n",
    "Le **GRU** (Gated Recurrent Unit) est un compromis entre SimpleRNN et LSTM : il a des portes comme le LSTM, mais avec une architecture plus simple (2 portes au lieu de 3). Il est souvent aussi performant que le LSTM mais plus rapide √† entra√Æner."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ü§ñ GEMINI\n",
    "\n",
    "Demandez √† Gemini :\n",
    "\n",
    "> *\"Cr√©e un mod√®le GRU avec la m√™me structure que le LSTM : 1 couche GRU(50), Dense(1), compile avec Adam et MSE. Entra√Æne pendant 20 epochs avec batch_size=32 et validation_data=(X_test, y_test). Mesure le temps d'entra√Ænement. Stocke dans `gru_model`, `history_gru`, `time_gru`. Affiche le summary.\"*\n",
    "\n",
    "Puis demandez :\n",
    "\n",
    "> *\"Quelle est la diff√©rence entre GRU et LSTM ? Lequel a le plus de param√®tres ? Pourquoi ?\"*"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# VOTRE CODE G√âN√âR√â PAR GEMINI ICI\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Visualiser les r√©sultats du GRU\n",
    "plot_training(history_gru, \"GRU\")\n",
    "\n",
    "y_pred_gru = gru_model.predict(X_test)\n",
    "plot_predictions(y_test, y_pred_gru, \"GRU\")\n",
    "\n",
    "rmse_gru = np.sqrt(mean_squared_error(y_test.flatten(), y_pred_gru.flatten()))\n",
    "print(f\"RMSE GRU : {rmse_gru:.4f}\")\n",
    "print(f\"Temps d'entra√Ænement : {time_gru:.1f}s\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚ùì QUESTION\n",
    "\n",
    "- Le GRU est-il plus rapide que le LSTM ? De combien ?\n",
    "- La performance (RMSE) est-elle comparable ?\n",
    "- Combien de param√®tres a le GRU par rapport au LSTM ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*(vos observations ici)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Exp√©rimentation B ‚Äî Empiler des couches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ü§ñ GEMINI\n",
    "\n",
    "Demandez √† Gemini :\n",
    "\n",
    "> *\"Cr√©e un mod√®le avec 2 couches LSTM empil√©es : LSTM(50, return_sequences=True) pour la premi√®re couche, LSTM(50) pour la deuxi√®me, puis Dense(1). Attention : la premi√®re couche doit avoir `return_sequences=True` pour transmettre la s√©quence compl√®te √† la couche suivante. Compile avec Adam et MSE. Entra√Æne 20 epochs, batch_size=32, validation_data=(X_test, y_test). Stocke dans `stacked_model`, `history_stacked`, `time_stacked`. Affiche le summary.\"*\n",
    "\n",
    "Puis demandez :\n",
    "\n",
    "> *\"Pourquoi faut-il `return_sequences=True` sur la premi√®re couche LSTM mais pas sur la derni√®re ?\"*"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# VOTRE CODE G√âN√âR√â PAR GEMINI ICI\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Visualiser les r√©sultats du mod√®le empil√©\n",
    "plot_training(history_stacked, \"LSTM empil√© (2 couches)\")\n",
    "\n",
    "y_pred_stacked = stacked_model.predict(X_test)\n",
    "plot_predictions(y_test, y_pred_stacked, \"LSTM empil√© (2 couches)\")\n",
    "\n",
    "rmse_stacked = np.sqrt(mean_squared_error(y_test.flatten(), y_pred_stacked.flatten()))\n",
    "print(f\"RMSE LSTM empil√© : {rmse_stacked:.4f}\")\n",
    "print(f\"Param√®tres : {stacked_model.count_params():,}\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚ùì QUESTION\n",
    "\n",
    "- Le mod√®le empil√© est-il meilleur que le LSTM √† 1 couche ?\n",
    "- Combien de param√®tres suppl√©mentaires a-t-il ?\n",
    "- L'ajout de profondeur aide-t-il toujours ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*(vos observations ici)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Exp√©rimentation C ‚Äî Ajouter du Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ü§ñ GEMINI\n",
    "\n",
    "Demandez √† Gemini :\n",
    "\n",
    "> *\"Cr√©e un mod√®le LSTM avec Dropout : LSTM(50), Dropout(0.2), Dense(1). Compile avec Adam et MSE. Entra√Æne 20 epochs, batch_size=32, validation_data=(X_test, y_test). Stocke dans `dropout_model`, `history_dropout`, `time_dropout`. Affiche le summary.\"*\n",
    "\n",
    "Puis demandez :\n",
    "\n",
    "> *\"Que fait le Dropout ? Pourquoi aide-t-il √† r√©duire l'overfitting ? Que signifie Dropout(0.2) ?\"*"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# VOTRE CODE G√âN√âR√â PAR GEMINI ICI\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Visualiser les r√©sultats du mod√®le avec Dropout\n",
    "plot_training(history_dropout, \"LSTM + Dropout\")\n",
    "\n",
    "y_pred_dropout = dropout_model.predict(X_test)\n",
    "plot_predictions(y_test, y_pred_dropout, \"LSTM + Dropout\")\n",
    "\n",
    "rmse_dropout = np.sqrt(mean_squared_error(y_test.flatten(), y_pred_dropout.flatten()))\n",
    "print(f\"RMSE LSTM + Dropout : {rmse_dropout:.4f}\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚ùì QUESTION\n",
    "\n",
    "- L'√©cart entre loss train et loss validation a-t-il diminu√© avec le Dropout ?\n",
    "- La RMSE est-elle meilleure ou moins bonne ?\n",
    "- Le Dropout r√©gularise-t-il efficacement ce mod√®le ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*(vos observations ici)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Exp√©rimentation D ‚Äî Changer la taille de la fen√™tre"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ü§ñ GEMINI\n",
    "\n",
    "Demandez √† Gemini :\n",
    "\n",
    "> *\"Teste le mod√®le LSTM avec deux tailles de fen√™tre diff√©rentes : window=20 et window=100. Pour chaque taille :\n",
    "> 1. Recr√©e les s√©quences X_train et X_test avec `create_sequences` et la nouvelle taille de fen√™tre\n",
    "> 2. Reshape les donn√©es en tenseur 3D\n",
    "> 3. Cr√©e un LSTM(50) + Dense(1), compile avec Adam et MSE\n",
    "> 4. Entra√Æne 20 epochs, batch_size=32\n",
    "> 5. Calcule la RMSE\n",
    ">\n",
    "> Affiche les pr√©dictions des deux mod√®les c√¥te √† c√¥te avec les RMSE dans les titres. Utilise `scaled_train` et `scaled_test` comme donn√©es source.\"*\n",
    "\n",
    "Puis demandez :\n",
    "\n",
    "> *\"Comment la taille de la fen√™tre affecte-t-elle les pr√©dictions ? Pourquoi une fen√™tre trop petite est probl√©matique ? Et trop grande ?\"*"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# VOTRE CODE G√âN√âR√â PAR GEMINI ICI\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚ùì QUESTION\n",
    "\n",
    "- Quelle taille de fen√™tre donne les meilleurs r√©sultats ?\n",
    "- Sachant que le cycle solaire dure environ 11 ans (~132 mois), une fen√™tre de 50 capture-t-elle un cycle complet ?\n",
    "- Y a-t-il un trade-off entre la taille de la fen√™tre et le nombre d'√©chantillons d'entra√Ænement ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*(vos observations ici)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## √âtape 6 ‚Äî TensorBoard\n",
    "\n",
    "TensorBoard permet de visualiser l'entra√Ænement en temps r√©el : loss, poids, distributions. On va r√©-entra√Æner notre meilleur mod√®le avec un callback TensorBoard."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "%load_ext tensorboard"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Cr√©er un nouveau mod√®le LSTM pour TensorBoard\n",
    "tb_model = Sequential([\n",
    "    LSTM(50, activation='relu', input_shape=(WINDOW_SIZE, 1)),\n",
    "    Dense(1)\n",
    "])\n",
    "\n",
    "tb_model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Callback TensorBoard\n",
    "logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)\n",
    "\n",
    "print(f\"Logs TensorBoard dans : {logdir}\")\n",
    "print(\"Entra√Ænement avec TensorBoard...\")\n",
    "\n",
    "tb_model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=20,\n",
    "    batch_size=32,\n",
    "    validation_data=(X_test, y_test),\n",
    "    callbacks=[tensorboard_callback]\n",
    ")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "%tensorboard --logdir logs"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ü§ñ GEMINI ‚Äî Comprendre TensorBoard\n",
    "\n",
    "Demandez √† Gemini :\n",
    "\n",
    "> *\"Explique-moi ce que montrent les onglets Scalars et Histograms dans TensorBoard. √Ä quoi servent-ils pour le diagnostic d'un mod√®le de deep learning ?\"*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## √âtape 7 ‚Äî Synth√®se\n",
    "\n",
    "Vous avez construit et compar√© plusieurs approches pour pr√©dire les taches solaires :\n",
    "\n",
    "| | SimpleRNN | LSTM | GRU |\n",
    "|---|---|---|---|\n",
    "| **Principe** | RNN basique, pas de portes | 3 portes (oubli, entr√©e, sortie) | 2 portes (reset, update) |\n",
    "| **M√©moire longue** | Faible (vanishing gradient) | Bonne | Bonne |\n",
    "| **Param√®tres** | Le moins | Le plus (~4x SimpleRNN) | Interm√©diaire (~3x SimpleRNN) |\n",
    "| **Vitesse** | Le plus rapide | Le plus lent | Interm√©diaire |\n",
    "| **Cas d'usage** | S√©quences courtes | S√©quences longues, d√©pendances complexes | Bon compromis performance/vitesse |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚ùì QUESTIONS FINALES\n",
    "\n",
    "1. **Cas d'usage** : dans votre domaine professionnel, imaginez un cas d'usage de RNN sur une s√©rie temporelle. D√©crivez-le en 2-3 phrases.\n",
    "\n",
    "2. **Conseil** : un coll√®gue veut pr√©dire des ventes mensuelles avec seulement 100 points de donn√©es. Que lui conseillez-vous ? Quel mod√®le ? Quelle taille de fen√™tre ?\n",
    "\n",
    "3. **Limites** : pourquoi le mod√®le a-t-il du mal avec les pics extr√™mes de la s√©rie ? Que pourrait-on faire pour am√©liorer les pr√©dictions ?\n",
    "\n",
    "4. **Surprise** : qu'est-ce qui vous a le plus surpris dans cet atelier ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*(vos r√©ponses ici)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Pour aller plus loin (optionnel)\n",
    "\n",
    "Si vous avez du temps et de la curiosit√©, voici quelques pistes d'exploration. Utilisez Gemini pour vous guider.\n",
    "\n",
    "- **Pr√©diction multi-step** : au lieu de pr√©dire 1 seul point, pr√©dire les 10 prochains points. Demandez √† Gemini *\"Modifie le mod√®le pour qu'il pr√©dise les 10 prochains points au lieu d'un seul. Comment faut-il changer la couche Dense de sortie et les cibles y ?\"*\n",
    "- **Bidirectional LSTM** : demandez √† Gemini *\"Enveloppe la couche LSTM dans un `Bidirectional()`. Quel avantage cela apporte-t-il pour une s√©rie temporelle ?\"*\n",
    "- **Autre dataset** : essayez avec des donn√©es de temp√©rature, de trafic web ou de cours de bourse\n",
    "- **Attention mechanism** : demandez √† Gemini *\"Ajoute une couche d'attention apr√®s le LSTM. Qu'est-ce que cela change ?\"*"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# VOTRE EXPLORATION ICI\n"
   ],
   "execution_count": null,
   "outputs": []
  }
 ]
}