{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Ouvrir sur Colab](https://colab.research.google.com/assets/colab-badge.svg)]",
    "(https://colab.research.google.com/github/SkatAI/deeplearning/blob/master/notebooks/transfer_learning_inception_fr.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning avec InceptionV3 sur Chats vs Chiens\n",
    "\n",
    "Ce notebook illustre le **transfer learning** en utilisant un modèle InceptionV3 pré-entraîné pour classifier des chats et des chiens.\n",
    "\n",
    "**Concepts clés :**\n",
    "- Transfer Learning : réutiliser les caractéristiques apprises sur ImageNet\n",
    "- Couches gelées : conserver les poids pré-entraînés inchangés\n",
    "- Tête personnalisée : ajouter un petit classifieur pour la classification binaire\n",
    "- Augmentation de données : améliorer la généralisation\n",
    "- Early Stopping : éviter le surapprentissage\n",
    "- TensorBoard : suivre l'entraînement en temps réel\n",
    "\n",
    "**Résultats attendus :**\n",
    "- Précision d'entraînement : ~95%+\n",
    "- Précision de validation : ~85%+ (bien meilleure qu'un entraînement from scratch)\n",
    "\n",
    "\n",
    "Documentation : [https://keras.io/guides/transfer_learning/](https://keras.io/guides/transfer_learning/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup : importer les bibliothèques et charger TensorBoard\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activer l'extension TensorBoard dans Jupyter\n",
    "%load_ext tensorboard\n",
    "\n",
    "# Importer les bibliothèques principales\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.keras import layers, Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import TensorBoard, EarlyStopping\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Importer les utilitaires\n",
    "import os\n",
    "import zipfile\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"GPU disponible: {tf.config.list_physical_devices('GPU')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Charger et configurer InceptionV3 pré-entraîné\n",
    "\n",
    "**Ce que nous faisons :**\n",
    "1. Créer un modèle InceptionV3 avec une entrée de forme (150, 150, 3)\n",
    "2. Retirer la couche de classification finale (`include_top=False`)\n",
    "3. Charger les poids pré-entraînés d'ImageNet via Keras (`weights='imagenet'`)\n",
    "4. Geler toutes les couches (`trainable=False`) pour qu'elles ne soient pas mises à jour pendant l'entraînement\n",
    "\n",
    "**Pourquoi geler ?**\n",
    "- Les caractéristiques pré-entraînées sont déjà excellentes pour détecter les bords, textures, formes, etc.\n",
    "- On veut uniquement apprendre la décision finale de classification chats vs chiens\n",
    "- Cela économise du calcul et évite le surapprentissage sur un petit jeu de données\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialiser le modèle InceptionV3 avec les poids pré-entraînés d'ImageNet\n",
    "# - input_shape=(150, 150, 3) : images RGB de 150x150\n",
    "# - include_top=False : retirer la couche de classification finale (on ajoutera la nôtre)\n",
    "# - weights='imagenet' : charger les poids pré-entraînés depuis Keras\n",
    "pre_trained_model = InceptionV3(\n",
    "    input_shape=(150, 150, 3),\n",
    "    include_top=False,\n",
    "    weights='imagenet'\n",
    ")\n",
    "\n",
    "# Geler toutes les couches pour qu'elles ne s'entraînent pas\n",
    "# On veut uniquement entraîner la couche de classification finale qu'on va ajouter\n",
    "for layer in pre_trained_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "print(f\"Nombre de couches dans InceptionV3 : {len(pre_trained_model.layers)}\")\n",
    "print(f\"Toutes les couches gelées : {not any(layer.trainable for layer in pre_trained_model.layers)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Examiner le modèle pré-entraîné\n",
    "\n",
    "Regardons l'architecture et la forme de sortie avec laquelle nous allons travailler.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Récupérer la couche de sortie qu'on utilisera comme base pour notre classifieur\n",
    "# 'mixed7' est l'un des derniers blocs convolutifs d'InceptionV3\n",
    "last_layer = pre_trained_model.get_layer('mixed7')\n",
    "\n",
    "print(f\"Nom de la dernière couche : {last_layer.name}\")\n",
    "# Utiliser model.output_shape au lieu de layer.output_shape\n",
    "print(f\"Forme de sortie de la dernière couche : {pre_trained_model.output_shape}\")\n",
    "print(f\"\\nLes caractéristiques d'InceptionV3 ont la forme : {pre_trained_model.output_shape[1:]}\")\n",
    "print(f\"(Ce sont 2048 cartes de caractéristiques de taille 4×4)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Résumé du modèle InceptionV3 :\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Nombre total de couches : {len(pre_trained_model.layers)}\")\n",
    "print(f\"Forme de sortie du modèle : {pre_trained_model.output_shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Construire la tête de classification personnalisée\n",
    "\n",
    "On ajoute un petit réseau de neurones au-dessus d'InceptionV3 pour la classification binaire.\n",
    "\n",
    "**Architecture :**\n",
    "```\n",
    "Sortie InceptionV3 (mixed7)\n",
    "    ↓\n",
    "GlobalAveragePooling2D → (768 neurones)\n",
    "    ↓\n",
    "Dense(1024) + ReLU ← Apprend la combinaison des caractéristiques\n",
    "    ↓\n",
    "Dropout(0.2) ← Régularisation (éviter le surapprentissage)\n",
    "    ↓\n",
    "Dense(1) + Sigmoid ← Sortie binaire (0=chat, 1=chien)\n",
    "```\n",
    "\n",
    "**Note :** On utilise `GlobalAveragePooling2D` au lieu de `Flatten` pour réduire drastiquement le nombre de paramètres et la consommation mémoire.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Récupérer la sortie de la dernière couche d'InceptionV3\n",
    "last_output = last_layer.output\n",
    "\n",
    "# Construire notre tête de classification personnalisée\n",
    "# Étape 1 : GlobalAveragePooling2D réduit chaque carte de caractéristiques à une seule valeur\n",
    "# Beaucoup plus efficace en mémoire que Flatten\n",
    "x = layers.GlobalAveragePooling2D()(last_output)\n",
    "\n",
    "# Étape 2 : Ajouter une couche dense avec 1024 neurones et activation ReLU\n",
    "# Cette couche apprend à combiner les caractéristiques pour la classification\n",
    "x = layers.Dense(1024, activation='relu')(x)\n",
    "\n",
    "# Étape 3 : Ajouter du dropout pour la régularisation\n",
    "# Désactive aléatoirement 20% des neurones pendant l'entraînement pour éviter le surapprentissage\n",
    "x = layers.Dropout(0.2)(x)\n",
    "\n",
    "# Étape 4 : Couche de sortie avec activation sigmoïde\n",
    "# La sigmoïde produit une valeur entre 0 et 1\n",
    "# 0 = chat, 1 = chien (classification binaire)\n",
    "x = layers.Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "# Créer le modèle final en connectant l'entrée d'InceptionV3 à notre sortie\n",
    "model = Model(pre_trained_model.input, x)\n",
    "\n",
    "print(\"Modèle personnalisé créé avec succès !\")\n",
    "print(f\"\\nLe modèle final a {len(model.layers)} couches au total\")\n",
    "print(f\"Seules les dernières couches s'entraînent (GlobalAveragePooling2D, Dense, Dropout, Dense)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Compiler le modèle\n",
    "\n",
    "**Paramètres de compilation :**\n",
    "- **Optimiseur** : Adam avec un faible taux d'apprentissage (0.0001) car on fait du fine-tuning\n",
    "- **Loss** : Binary crossentropy (pour la classification binaire)\n",
    "- **Métriques** : Accuracy pour suivre les performances\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiler le modèle\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=0.0001),  # Faible taux d'apprentissage pour le fine-tuning\n",
    "    loss='binary_crossentropy',             # Loss pour la classification binaire\n",
    "    metrics=['accuracy']                    # Suivre la précision pendant l'entraînement\n",
    ")\n",
    "\n",
    "print(\"Modèle compilé avec succès !\")\n",
    "\n",
    "# Afficher le résumé des couches entraînables\n",
    "print(\"\\nRésumé du modèle (couches principales) :\")\n",
    "print(\"=\"*80)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Télécharger et extraire le jeu de données\n",
    "\n",
    "On télécharge le jeu de données Microsoft chats et chiens (~65 Mo compressé).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Télécharger le jeu de données\n",
    "print(\"Téléchargement du jeu de données chats et chiens (cela peut prendre 2-5 minutes)...\")\n",
    "!wget https://storage.googleapis.com/tensorflow-1-public/course2/cats_and_dogs_filtered.zip\n",
    "\n",
    "# Extraire le jeu de données\n",
    "print(\"\\nExtraction du jeu de données...\")\n",
    "zip_ref = zipfile.ZipFile(\"./cats_and_dogs_filtered.zip\", 'r')\n",
    "zip_ref.extractall(\"tmp/\")\n",
    "zip_ref.close()\n",
    "\n",
    "print(\"Jeu de données extrait avec succès !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Configurer les chemins des données\n",
    "\n",
    "Organiser les répertoires d'entraînement et de validation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définir le répertoire de base\n",
    "base_dir = 'tmp/cats_and_dogs_filtered'\n",
    "\n",
    "# Répertoires d'entraînement\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "train_cats_dir = os.path.join(train_dir, 'cats')\n",
    "train_dogs_dir = os.path.join(train_dir, 'dogs')\n",
    "\n",
    "# Répertoires de validation\n",
    "validation_dir = os.path.join(base_dir, 'validation')\n",
    "validation_cats_dir = os.path.join(validation_dir, 'cats')\n",
    "validation_dogs_dir = os.path.join(validation_dir, 'dogs')\n",
    "\n",
    "# Compter les images\n",
    "num_train_cats = len(os.listdir(train_cats_dir))\n",
    "num_train_dogs = len(os.listdir(train_dogs_dir))\n",
    "num_val_cats = len(os.listdir(validation_cats_dir))\n",
    "num_val_dogs = len(os.listdir(validation_dogs_dir))\n",
    "\n",
    "print(\"Structure du jeu de données :\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Jeu d'entraînement :\")\n",
    "print(f\"  - Chats : {num_train_cats}\")\n",
    "print(f\"  - Chiens : {num_train_dogs}\")\n",
    "print(f\"  - Total : {num_train_cats + num_train_dogs}\")\n",
    "print(f\"\\nJeu de validation :\")\n",
    "print(f\"  - Chats : {num_val_cats}\")\n",
    "print(f\"  - Chiens : {num_val_dogs}\")\n",
    "print(f\"  - Total : {num_val_cats + num_val_dogs}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Créer les générateurs de données avec augmentation\n",
    "\n",
    "L'**augmentation de données** applique des transformations aléatoires aux images d'entraînement pour :\n",
    "- Augmenter la taille effective du jeu de données\n",
    "- Améliorer la généralisation du modèle\n",
    "- Éviter le surapprentissage\n",
    "\n",
    "**Augmentations appliquées :**\n",
    "- Rotation : ±40°\n",
    "- Décalage largeur/hauteur : 20%\n",
    "- Zoom : 20%\n",
    "- Retournement horizontal : aléatoire\n",
    "\n",
    "**Note :** On n'augmente pas les données de validation (uniquement la normalisation) pour obtenir des métriques de performance fiables.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Générateur de données d'entraînement AVEC augmentation\n",
    "# Ces transformations aident le modèle à mieux généraliser\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1.0/255.,           # Normaliser les valeurs des pixels dans [0, 1]\n",
    "    rotation_range=40,          # Rotations aléatoires jusqu'à 40 degrés\n",
    "    width_shift_range=0.2,      # Décalages horizontaux aléatoires jusqu'à 20%\n",
    "    height_shift_range=0.2,     # Décalages verticaux aléatoires jusqu'à 20%\n",
    "    shear_range=0.2,            # Transformations de cisaillement aléatoires\n",
    "    zoom_range=0.2,             # Zoom aléatoire jusqu'à 20%\n",
    "    horizontal_flip=True,       # Retournements horizontaux aléatoires\n",
    "    fill_mode='nearest'         # Mode de remplissage pour les pixels hors limites\n",
    ")\n",
    "\n",
    "# Générateur de données de validation SANS augmentation\n",
    "# On normalise uniquement, pas d'autres transformations\n",
    "# Cela garantit une évaluation sur des données réalistes non augmentées\n",
    "test_datagen = ImageDataGenerator(\n",
    "    rescale=1.0/255.            # Normaliser les valeurs des pixels dans [0, 1]\n",
    ")\n",
    "\n",
    "# Créer le générateur de données d'entraînement\n",
    "# Charge automatiquement les images depuis les répertoires et applique l'augmentation\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    batch_size=20,              # Charger 20 images à la fois\n",
    "    class_mode='binary',        # Classification binaire (chats=0, chiens=1)\n",
    "    target_size=(150, 150)      # Redimensionner toutes les images en 150×150\n",
    ")\n",
    "\n",
    "# Créer le générateur de données de validation\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    validation_dir,\n",
    "    batch_size=20,              # Charger 20 images à la fois\n",
    "    class_mode='binary',        # Classification binaire\n",
    "    target_size=(150, 150)      # Redimensionner toutes les images en 150×150\n",
    ")\n",
    "\n",
    "print(\"Générateurs de données créés avec succès !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Configurer les callbacks : Early Stopping et TensorBoard\n",
    "\n",
    "**Early Stopping :**\n",
    "- Surveille la loss de validation\n",
    "- Arrête l'entraînement si la loss de validation ne s'améliore pas pendant 3 epochs\n",
    "- Sauvegarde les meilleurs poids du modèle\n",
    "- Évite le surapprentissage et fait gagner du temps\n",
    "\n",
    "**TensorBoard :**\n",
    "- Enregistre les métriques d'entraînement (loss, accuracy)\n",
    "- Enregistre les histogrammes des poids\n",
    "- Permet le suivi en temps réel et la comparaison\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Créer un répertoire de logs unique pour cet entraînement\n",
    "log_dir = \"logs/inception_v3_\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "# Configurer le callback Early Stopping\n",
    "# Arrête l'entraînement si la loss de validation cesse de s'améliorer\n",
    "early_stop = EarlyStopping(\n",
    "    monitor='val_loss',         # Surveiller la loss de validation\n",
    "    patience=3,                 # Arrêter si pas d'amélioration pendant 3 epochs\n",
    "    restore_best_weights=True,  # Restaurer les poids de la meilleure epoch\n",
    "    verbose=1                   # Afficher un message à l'arrêt\n",
    ")\n",
    "\n",
    "# Configurer le callback TensorBoard\n",
    "# Enregistre les métriques d'entraînement pour la visualisation\n",
    "tensorboard_callback = TensorBoard(\n",
    "    log_dir=log_dir,            # Répertoire de sauvegarde des logs\n",
    "    histogram_freq=1            # Sauvegarder les histogrammes des poids à chaque epoch\n",
    ")\n",
    "\n",
    "print(f\"Callbacks configurés :\")\n",
    "print(f\"  - Early Stopping : patience=3 epochs\")\n",
    "print(f\"  - TensorBoard : {log_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Entraîner le modèle\n",
    "\n",
    "On lance maintenant l'entraînement du modèle avec les callbacks.\n",
    "\n",
    "**Détails de l'entraînement :**\n",
    "- Seule la tête personnalisée s'entraîne (les couches d'InceptionV3 sont gelées)\n",
    "- steps_per_epoch=100 : traiter 100 batchs de 20 images par epoch = ~2000 images\n",
    "- validation_steps=50 : traiter 50 batchs de 20 images pour la validation = ~1000 images\n",
    "- epochs=10 : maximum 10 epochs (peut s'arrêter plus tôt si l'Early Stopping se déclenche)\n",
    "\n",
    "**Temps estimé :** 2-5 minutes par epoch sur GPU, 10-20 minutes sur CPU\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entraîner le modèle\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=validation_generator,\n",
    "    steps_per_epoch=100,        # Nombre de batchs par epoch\n",
    "    validation_steps=50,        # Nombre de batchs pour la validation\n",
    "    epochs=10,                  # Nombre maximum d'epochs\n",
    "    callbacks=[early_stop, tensorboard_callback],  # Appliquer les callbacks\n",
    "    verbose=1                   # Afficher la progression\n",
    ")\n",
    "\n",
    "print(\"\\nEntraînement terminé !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Lancer TensorBoard\n",
    "\n",
    "Visualiser les métriques d'entraînement, les distributions des poids et l'architecture du modèle dans TensorBoard.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lancer TensorBoard\n",
    "%tensorboard --logdir logs\n",
    "\n",
    "print(\"TensorBoard est maintenant actif !\")\n",
    "print(f\"Voir sur : http://localhost:6006\")\n",
    "print(f\"\\nVous pouvez voir :\")\n",
    "print(f\"  - Scalars : graphiques de loss et accuracy\")\n",
    "print(f\"  - Histograms : distributions des poids par couche\")\n",
    "print(f\"  - Graph : architecture du modèle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Évaluer et visualiser les résultats\n",
    "\n",
    "Tracer les métriques d'entraînement vs validation pour évaluer les performances du modèle et le surapprentissage.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraire les métriques de l'historique\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "# Créer les numéros d'epochs\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "# Créer une figure avec 2 sous-graphiques\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Graphique 1 : Accuracy\n",
    "ax1.plot(epochs, acc, 'r-', label='Accuracy entraînement', linewidth=2)\n",
    "ax1.plot(epochs, val_acc, 'b-', label='Accuracy validation', linewidth=2)\n",
    "ax1.set_title('Accuracy entraînement vs validation', fontsize=14, fontweight='bold')\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Accuracy')\n",
    "ax1.legend(loc='lower right')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "ax1.set_ylim([0, 1])\n",
    "\n",
    "# Graphique 2 : Loss\n",
    "ax2.plot(epochs, loss, 'r-', label='Loss entraînement', linewidth=2)\n",
    "ax2.plot(epochs, val_loss, 'b-', label='Loss validation', linewidth=2)\n",
    "ax2.set_title('Loss entraînement vs validation', fontsize=14, fontweight='bold')\n",
    "ax2.set_xlabel('Epoch')\n",
    "ax2.set_ylabel('Loss')\n",
    "ax2.legend(loc='upper right')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Afficher le résumé des statistiques\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"RÉSUMÉ DES RÉSULTATS D'ENTRAÎNEMENT\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nEpoch finale : {len(epochs)}\")\n",
    "print(f\"\\nMétriques d'entraînement :\")\n",
    "print(f\"  - Accuracy : {acc[-1]:.4f} ({acc[-1]*100:.2f}%)\")\n",
    "print(f\"  - Loss : {loss[-1]:.4f}\")\n",
    "print(f\"\\nMétriques de validation :\")\n",
    "print(f\"  - Accuracy : {val_acc[-1]:.4f} ({val_acc[-1]*100:.2f}%)\")\n",
    "print(f\"  - Loss : {val_loss[-1]:.4f}\")\n",
    "print(f\"\\nÉcart (indicateur de surapprentissage) :\")\n",
    "print(f\"  - Écart d'accuracy : {(acc[-1] - val_acc[-1])*100:.2f}%\")\n",
    "print(f\"  - Écart de loss : {loss[-1] - val_loss[-1]:.4f}\")\n",
    "\n",
    "if acc[-1] - val_acc[-1] < 0.10:\n",
    "    print(f\"\\n✓ Bonne généralisation ! L'écart est inférieur à 10%\")\n",
    "elif acc[-1] - val_acc[-1] < 0.20:\n",
    "    print(f\"\\n⚠ Surapprentissage modéré détecté. Envisagez plus de régularisation.\")\n",
    "else:\n",
    "    print(f\"\\n✗ Surapprentissage significatif. Le modèle a mémorisé les données d'entraînement.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Sauvegarder le modèle entraîné\n",
    "\n",
    "Sauvegarder le modèle pour une utilisation future ou un déploiement.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sauvegarder le modèle\n",
    "model_save_path = 'inception_v3_cats_dogs.h5'\n",
    "model.save(model_save_path)\n",
    "\n",
    "print(f\"Modèle sauvegardé dans : {model_save_path}\")\n",
    "print(f\"\\nVous pouvez le charger plus tard avec :\")\n",
    "print(f\"  from tensorflow.keras.models import load_model\")\n",
    "print(f\"  model = load_model('{model_save_path}')\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. Tester les prédictions (optionnel)\n",
    "\n",
    "Faire des prédictions sur quelques images de validation pour voir comment le modèle se comporte.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from tensorflow.keras.preprocessing import image as keras_image\n",
    "\n",
    "# Récupérer un batch d'exemple du générateur de validation\n",
    "val_images, val_labels = next(validation_generator)\n",
    "\n",
    "# Faire les prédictions\n",
    "predictions = model.predict(val_images[:8])\n",
    "\n",
    "# Visualiser les prédictions\n",
    "fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, (image, label, pred) in enumerate(zip(val_images[:8], val_labels[:8], predictions[:8])):\n",
    "    # Dénormaliser l'image pour l'affichage\n",
    "    image_display = (image * 255).astype(np.uint8)\n",
    "\n",
    "    # Obtenir les labels vrais et prédits\n",
    "    true_label = \"Chien\" if label == 1 else \"Chat\"\n",
    "    pred_prob = pred[0]\n",
    "    pred_label = \"Chien\" if pred_prob > 0.5 else \"Chat\"\n",
    "    confidence = max(pred_prob, 1 - pred_prob) * 100\n",
    "\n",
    "    # Couleur : vert si correct, rouge si faux\n",
    "    is_correct = (label == 1 and pred_prob > 0.5) or (label == 0 and pred_prob <= 0.5)\n",
    "    color = 'green' if is_correct else 'red'\n",
    "\n",
    "    # Afficher\n",
    "    axes[i].imshow(image_display.astype('uint8'))\n",
    "    axes[i].set_title(f'Vrai : {true_label}\\nPréd : {pred_label} ({confidence:.1f}%)',\n",
    "                     color=color, fontweight='bold')\n",
    "    axes[i].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nPrédictions d'exemple terminées !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Résumé\n",
    "\n",
    "**Ce que nous avons accompli :**\n",
    "\n",
    "1. ✓ Chargé le modèle InceptionV3 pré-entraîné (entraîné sur ImageNet)\n",
    "2. ✓ Gelé toutes les couches pour préserver les caractéristiques apprises\n",
    "3. ✓ Ajouté une tête de classification personnalisée (Flatten + Dense + Dropout + Dense)\n",
    "4. ✓ Appliqué l'augmentation de données pour éviter le surapprentissage\n",
    "5. ✓ Entraîné avec le callback Early Stopping (évite l'entraînement inutile)\n",
    "6. ✓ Suivi l'entraînement avec TensorBoard\n",
    "7. ✓ Obtenu une haute précision sur la classification chats vs chiens\n",
    "\n",
    "**Avantages du Transfer Learning :**\n",
    "- Entraînement beaucoup plus rapide (minutes au lieu d'heures)\n",
    "- Meilleure précision avec peu de données (haute accuracy en validation)\n",
    "- Exploite les connaissances de plus d'1M d'images ImageNet\n",
    "- Risque réduit de surapprentissage\n",
    "\n",
    "**Prochaines étapes :**\n",
    "- Fine-tuner avec `model.trainable = True` et un très faible taux d'apprentissage pour améliorer la précision\n",
    "- Tester sur vos propres images\n",
    "- Déployer le modèle en production\n",
    "- Expérimenter avec d'autres modèles pré-entraînés (ResNet, MobileNet, etc.)\n"
   ]
  }
 ]
}