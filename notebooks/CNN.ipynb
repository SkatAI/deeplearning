{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# CNN\n",
        "\n",
        "Dans ce notebook nous allons implementer un CNN sur le dataset Cats vs Dogs\n"
      ],
      "metadata": {
        "id": "Yd6rorvZMIMB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ba1AehVSMFNr"
      },
      "outputs": [],
      "source": [
        "!wget --no-check-certificate https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "\n",
        "# Unzip the archive\n",
        "local_zip = './cats_and_dogs_filtered.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall()\n",
        "\n",
        "zip_ref.close()"
      ],
      "metadata": {
        "id": "pY_ICCSyQuaB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -al"
      ],
      "metadata": {
        "id": "MX37J80xQ_e2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm cats_and_dogs_filtered.zip"
      ],
      "metadata": {
        "id": "R8265exERCbk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -al ./cats_and_dogs_filtered/"
      ],
      "metadata": {
        "id": "vziXzu8_RQv6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -al ./cats_and_dogs_filtered/train/cats | head\n"
      ],
      "metadata": {
        "id": "55jMwDazQx_2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Explorer le dataset"
      ],
      "metadata": {
        "id": "9ZxRrC04Rd_F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "base_dir = \"./cats_and_dogs_filtered/\"\n",
        "train_dir = os.path.join(base_dir, 'train')\n",
        "validation_dir = os.path.join(base_dir, 'validation')\n",
        "\n",
        "# Directory with training cat/dog pictures\n",
        "train_cats_dir = os.path.join(train_dir, 'cats')\n",
        "train_dogs_dir = os.path.join(train_dir, 'dogs')\n",
        "\n",
        "# Directory with validation cat/dog pictures\n",
        "validation_cats_dir = os.path.join(validation_dir, 'cats')\n",
        "validation_dogs_dir = os.path.join(validation_dir, 'dogs')\n",
        "train_cat_fnames = os.listdir( train_cats_dir )\n",
        "train_dog_fnames = os.listdir( train_dogs_dir )\n"
      ],
      "metadata": {
        "id": "9EiQVS0WRs3o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_cat_fnames[:10]"
      ],
      "metadata": {
        "id": "kGTDz0w0R9OX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.image as mpimg\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Parameters for our graph; we'll output images in a 4x4 configuration\n",
        "nrows = 4\n",
        "ncols = 4\n",
        "\n",
        "pic_index = 0 # Index for iterating over images\n",
        "\n",
        "# Set up matplotlib fig, and size it to fit 4x4 pics\n",
        "fig = plt.gcf()\n",
        "fig.set_size_inches(ncols*4, nrows*4)\n",
        "\n",
        "pic_index+=8\n",
        "\n",
        "next_cat_pix = [os.path.join(train_cats_dir, fname)\n",
        "                for fname in train_cat_fnames[ pic_index-8:pic_index]\n",
        "               ]\n",
        "\n",
        "next_dog_pix = [os.path.join(train_dogs_dir, fname)\n",
        "                for fname in train_dog_fnames[ pic_index-8:pic_index]\n",
        "               ]\n",
        "\n",
        "for i, img_path in enumerate(next_cat_pix+next_dog_pix):\n",
        "  # Set up subplot; subplot indices start at 1\n",
        "  sp = plt.subplot(nrows, ncols, i + 1)\n",
        "  sp.axis('Off') # Don't show axes (or gridlines)\n",
        "\n",
        "  img = mpimg.imread(img_path)\n",
        "  plt.imshow(img)\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "VO7KgUidQ1Dk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Simple CNN\n",
        "\n"
      ],
      "metadata": {
        "id": "FodfYgeiSRD-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "    # Note the input shape is the desired size of the image 150x150 with 3 bytes color\n",
        "    tf.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(150, 150, 3)),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    # Flatten the results to feed into a DNN\n",
        "    tf.keras.layers.Flatten(),\n",
        "    # 512 neuron hidden layer\n",
        "    tf.keras.layers.Dense(512, activation='relu'),\n",
        "    # Only 1 output neuron. It will contain a value from 0-1 where 0 for 1 class ('cats') and 1 for the other ('dogs')\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])"
      ],
      "metadata": {
        "id": "NokLVpXZRhux"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "bPVqruBGSXAt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.optimizers import RMSprop\n",
        "\n",
        "model.compile(optimizer=RMSprop(learning_rate=0.001),\n",
        "              loss='binary_crossentropy',\n",
        "              metrics = ['accuracy'])"
      ],
      "metadata": {
        "id": "RxqotgVMSYjS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# All images will be rescaled by 1./255.\n",
        "train_datagen = ImageDataGenerator( rescale = 1.0/255. )\n",
        "test_datagen  = ImageDataGenerator( rescale = 1.0/255. )\n",
        "\n",
        "# --------------------\n",
        "# Flow training images in batches of 20 using train_datagen generator\n",
        "# --------------------\n",
        "train_generator = train_datagen.flow_from_directory(train_dir,\n",
        "                                                    batch_size=20,\n",
        "                                                    class_mode='binary',\n",
        "                                                    target_size=(150, 150))\n",
        "# --------------------\n",
        "# Flow validation images in batches of 20 using test_datagen generator\n",
        "# --------------------\n",
        "validation_generator =  test_datagen.flow_from_directory(validation_dir,\n",
        "                                                         batch_size=20,\n",
        "                                                         class_mode  = 'binary',\n",
        "                                                         target_size = (150, 150))\n"
      ],
      "metadata": {
        "id": "EM3Y2etcS5IO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "            train_generator,\n",
        "            epochs=2,\n",
        "            validation_data=validation_generator,\n",
        "            verbose=2\n",
        "            )"
      ],
      "metadata": {
        "id": "MdEnohurS8bH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history.history[     'accuracy' ]"
      ],
      "metadata": {
        "id": "rVXj6VKBQ_Fu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# overfit ?\n"
      ],
      "metadata": {
        "id": "SO3Tgk4wQRLg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#-----------------------------------------------------------\n",
        "# Retrieve a list of list results on training and test data\n",
        "# sets for each training epoch\n",
        "#-----------------------------------------------------------\n",
        "acc      = history.history[     'accuracy' ]\n",
        "val_acc  = history.history[ 'val_accuracy' ]\n",
        "loss     = history.history[    'loss' ]\n",
        "val_loss = history.history['val_loss' ]\n",
        "\n",
        "epochs   = range(len(acc)) # Get number of epochs\n",
        "\n",
        "#------------------------------------------------\n",
        "# Plot training and validation accuracy per epoch\n",
        "#------------------------------------------------\n",
        "plt.plot  ( epochs,     acc )\n",
        "plt.plot  ( epochs, val_acc )\n",
        "plt.title ('Training and validation accuracy')\n",
        "plt.figure()\n",
        "\n",
        "#------------------------------------------------\n",
        "# Plot training and validation loss per epoch\n",
        "#------------------------------------------------\n",
        "plt.plot  ( epochs,     loss )\n",
        "plt.plot  ( epochs, val_loss )\n",
        "plt.title ('Training and validation loss'   )"
      ],
      "metadata": {
        "id": "0YZr28YdQToV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Voir les representations intermediaires"
      ],
      "metadata": {
        "id": "F5vc-jXAPs4J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import random\n",
        "from tensorflow.keras.utils import img_to_array, load_img\n"
      ],
      "metadata": {
        "id": "PMZywOTlTBiK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "successive_outputs = [layer.output for layer in model.layers]\n",
        "visualization_model = tf.keras.models.Model(inputs = model.input, outputs = successive_outputs)\n",
        "\n",
        "# Prepare a random input image from the training set.\n",
        "cat_img_files = [os.path.join(train_cats_dir, f) for f in train_cat_fnames]\n",
        "dog_img_files = [os.path.join(train_dogs_dir, f) for f in train_dog_fnames]\n",
        "img_path = random.choice(cat_img_files + dog_img_files)\n",
        "img = load_img(img_path, target_size=(150, 150))  # this is a PIL image\n",
        "x   = img_to_array(img)                           # Numpy array with shape (150, 150, 3)\n",
        "x   = x.reshape((1,) + x.shape)                   # Numpy array with shape (1, 150, 150, 3)\n",
        "\n",
        "# Scale by 1/255\n",
        "x /= 255.0\n"
      ],
      "metadata": {
        "id": "tmmFSCNQPxX4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "successive_feature_maps = visualization_model.predict(x)\n"
      ],
      "metadata": {
        "id": "bp1x2tpRP8bE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "layer_names = [layer.name for layer in model.layers]\n"
      ],
      "metadata": {
        "id": "0tO4cf3QP-PA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for layer_name, feature_map in zip(layer_names, successive_feature_maps):\n",
        "\n",
        "  if len(feature_map.shape) == 4:\n",
        "\n",
        "    #-------------------------------------------\n",
        "    # Just do this for the conv / maxpool layers, not the fully-connected layers\n",
        "    #-------------------------------------------\n",
        "    n_features = feature_map.shape[-1]  # number of features in the feature map\n",
        "    size       = feature_map.shape[ 1]  # feature map shape (1, size, size, n_features)\n",
        "\n",
        "    # Tile the images in this matrix\n",
        "    display_grid = np.zeros((size, size * n_features))\n",
        "\n",
        "    #-------------------------------------------------\n",
        "    # Postprocess the feature to be visually palatable\n",
        "    #-------------------------------------------------\n",
        "    for i in range(n_features):\n",
        "      x  = feature_map[0, :, :, i]\n",
        "      x -= x.mean()\n",
        "      x /= x.std ()\n",
        "      x *=  64\n",
        "      x += 128\n",
        "      x  = np.clip(x, 0, 255).astype('uint8')\n",
        "      display_grid[:, i * size : (i + 1) * size] = x # Tile each filter into a horizontal grid\n",
        "\n",
        "    #-----------------\n",
        "    # Display the grid\n",
        "    #-----------------\n",
        "    scale = 20. / n_features\n",
        "    plt.figure( figsize=(scale * n_features, scale) )\n",
        "    plt.title ( layer_name )\n",
        "    plt.grid  ( False )\n",
        "    plt.imshow( display_grid, aspect='auto', cmap='viridis' )"
      ],
      "metadata": {
        "id": "8OI_GSGdQBJr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# terminate\n",
        "\n",
        "import os, signal\n",
        "\n",
        "os.kill(os.getpid(), signal.SIGKILL)"
      ],
      "metadata": {
        "id": "4lgpXuawQZXv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os, signal\n",
        "\n",
        "os.kill(os.getpid(), signal.SIGKILL)"
      ],
      "metadata": {
        "id": "GK7E7QsLQEGR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vVRFfDK2Qcb-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}