{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yd6rorvZMIMB"
   },
   "source": [
    "# CNN\n",
    "\n",
    "Dans ce notebook nous allons implementer un CNN sur le dataset cats vs Dogs\n",
    "\n",
    "Nous utliserons tensorboard pour surveiller le comportement du modele pendant son entrainement, par exemple pour detecter si le modele overfit\n",
    "\n",
    "enfin nous allons remedier au probleme ainsi detecté\n",
    "\n",
    "Le notebook comporte 3 parties\n",
    "\n",
    "- dataset, chargement, visualisation et formatage\n",
    "- definition, compilation du modele\n",
    "- entrainement, observation et remediation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QDS8mPIRcsS9"
   },
   "outputs": [],
   "source": [
    "# pour charger l'extension tensorboard\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installer kagglehub pour télécharger le dataset\n",
    "!pip -q install kagglehub\n",
    "\n",
    "import kagglehub\n",
    "import os\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ba1AehVSMFNr"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"birajsth/cats-and-dogs-filtered\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pY_ICCSyQuaB"
   },
   "outputs": [],
   "source": [
    "# kagglehub télécharge et dézippe automatiquement\n",
    "\n",
    "# Le dataset est dans un sous-dossier \"cats_and_dogs_filtered\"\n",
    "base_dir = os.path.join(path, \"cats_and_dogs_filtered\")\n",
    "base_dir\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lEqt9CSR-nMv"
   },
   "source": [
    "# Dataset\n",
    "\n",
    "- Ou se trouve le dataset ?\n",
    "- De quoi est il constitué ?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vziXzu8_RQv6"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sKsr7K63-yx5"
   },
   "source": [
    "le dataset est scindé en une partie d'entrainement et une partie de test.\n",
    "\n",
    "\n",
    "Qui a t il dans le  repertoires de train ?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "55jMwDazQx_2"
   },
   "outputs": [],
   "source": [
    "!ls -al {base_dir}\n",
    "!ls -al {base_dir}/train/cats | head\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9ZxRrC04Rd_F"
   },
   "source": [
    "## Explorer le dataset\n",
    "\n",
    "On defini les repertoires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9EiQVS0WRs3o"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "validation_dir = os.path.join(base_dir, 'validation')\n",
    "\n",
    "# Directory with training cat/dog pictures\n",
    "train_cats_dir = os.path.join(train_dir, 'cats')\n",
    "train_dogs_dir = os.path.join(train_dir, 'dogs')\n",
    "\n",
    "# Directory with validation cat/dog pictures\n",
    "validation_cats_dir = os.path.join(validation_dir, 'cats')\n",
    "validation_dogs_dir = os.path.join(validation_dir, 'dogs')\n",
    "train_cat_fnames = os.listdir( train_cats_dir )\n",
    "train_dog_fnames = os.listdir( train_dogs_dir )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MuUhHEP7EzNo"
   },
   "source": [
    "Les fichiers `train_cat_fnames` et `train_dog_fnames` contiennent les noms des fichiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kGTDz0w0R9OX"
   },
   "outputs": [],
   "source": [
    "train_cat_fnames[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4FNnIZSCGph2"
   },
   "source": [
    "### structure des données\n",
    "\n",
    "pour etre commpatible avec les outils de tranformation Keras\n",
    "\n",
    "```\n",
    "/data/\n",
    "    /train/\n",
    "        /class1/\n",
    "            img1.jpg\n",
    "            img2.jpg\n",
    "            ...\n",
    "        /class2/\n",
    "            img1.jpg\n",
    "            img2.jpg\n",
    "            ...\n",
    "    /validation/\n",
    "        /class1/\n",
    "            img1.jpg\n",
    "            img2.jpg\n",
    "            ...\n",
    "        /class2/\n",
    "            img1.jpg\n",
    "            img2.jpg\n",
    "            ...\n",
    "\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a8B92X1mE-ZN"
   },
   "source": [
    "# Chats et chiens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VO7KgUidQ1Dk"
   },
   "outputs": [],
   "source": [
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Parameters for our graph; we'll output images in a 4x4 configuration\n",
    "nrows = 4\n",
    "ncols = 4\n",
    "\n",
    "# images a partir de l'index :\n",
    "pic_index = 250\n",
    "\n",
    "# list des 8 images de chats et chiens\n",
    "next_cat_pix = [os.path.join(train_cats_dir, fname) for fname in train_cat_fnames[ pic_index:pic_index +8] ]\n",
    "\n",
    "next_dog_pix = [os.path.join(train_dogs_dir, fname) for fname in train_dog_fnames[ pic_index:pic_index +8]]\n",
    "\n",
    "\n",
    "# un grid de 4x4\n",
    "\n",
    "fig, ax = plt.subplots(ncols*4, nrows*4, figsize = (12,12))\n",
    "for i, img_path in enumerate(next_cat_pix+next_dog_pix):\n",
    "  sp = plt.subplot(nrows, ncols, i + 1)\n",
    "  sp.axis('Off') # Don't show axes (or gridlines)\n",
    "\n",
    "  img = mpimg.imread(img_path)\n",
    "  plt.imshow(img)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mu-kWooWFSA0"
   },
   "source": [
    "Adorables!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4oXtObBSFUc_"
   },
   "source": [
    "# formatter les images\n",
    "\n",
    "on va\n",
    "- normalizer les valeurs (diviser par 255)\n",
    "- utiliser  [_ImageDataGenerator_](https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator) pour traiter toutes les images des repertoires d'entrainement et de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EM3Y2etcS5IO"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# All images will be rescaled by 1./255.\n",
    "train_datagen = ImageDataGenerator( rescale = 1.0/255. )\n",
    "test_datagen  = ImageDataGenerator( rescale = 1.0/255. )\n",
    "\n",
    "# --------------------\n",
    "# Flow training images in batches of 20 using train_datagen generator\n",
    "# --------------------\n",
    "train_generator = train_datagen.flow_from_directory(train_dir,\n",
    "                                                    batch_size=16,\n",
    "                                                    class_mode='binary',\n",
    "                                                    target_size=(150, 150))\n",
    "# --------------------\n",
    "# Flow validation images in batches of 20 using test_datagen generator\n",
    "# --------------------\n",
    "validation_generator =  test_datagen.flow_from_directory(validation_dir,\n",
    "                                                         batch_size=16,\n",
    "                                                         class_mode  = 'binary',\n",
    "                                                         target_size = (150, 150))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FodfYgeiSRD-"
   },
   "source": [
    "# Simple CNN\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Description du modèle\n",
    "- **Entrée** : images 150×150×3 (RGB).\n",
    "- **Extraction de motifs** : une couche Conv2D apprend des filtres locaux (bords, textures).\n",
    "- **Réduction** : MaxPooling2D diminue la résolution et garde l’essentiel.\n",
    "- **Aplatissement** : Flatten transforme les cartes de caractéristiques en vecteur.\n",
    "- **Apprentissage non‑linéaire** : Dense(128) pour combiner les features.\n",
    "- **Régularisation** : Dropout(0.2) limite le sur‑apprentissage.\n",
    "- **Sortie binaire** : Dense(1) + sigmoïde → probabilité chat vs chien.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NokLVpXZRhux"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "def create_model():\n",
    "    model = tf.keras.models.Sequential([\n",
    "        # Note the input shape is the desired size of the image 150x150 with 3 bytes color\n",
    "        tf.keras.layers.Input(shape=(150, 150, 3)),\n",
    "        tf.keras.layers.Conv2D(16, (3,3), activation='relu'),\n",
    "        tf.keras.layers.MaxPooling2D(2,2),\n",
    "        # <ajouter des layers Conv2D et MaxPooling ?>\n",
    "        # Flatten the results to feed into a DNN\n",
    "        tf.keras.layers.Flatten(),\n",
    "        # 512 neuron hidden layer\n",
    "        tf.keras.layers.Dense(128, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        # Only 1 output neuron. It will contain a value from 0-1 where 0 for 1 class ('cats') and 1 for the other ('dogs')\n",
    "        tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "\n",
    "\n",
    "    model.compile(optimizer=RMSprop(learning_rate=0.01),\n",
    "                loss='binary_crossentropy',\n",
    "                metrics = ['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bPVqruBGSXAt"
   },
   "outputs": [],
   "source": [
    "model = create_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_oo0efiv9LTm"
   },
   "source": [
    "# Monitorer le training avec tensorboard\n",
    "\n",
    "On crée un callback TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "90FOGYMoc-Sr"
   },
   "outputs": [],
   "source": [
    "import datetime, os\n",
    "logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "#  https://keras.io/api/callbacks/tensorboard/\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3FSxm-IO9S58"
   },
   "source": [
    "### Lancer tensorboard\n",
    "\n",
    "Lancer tensorboard avant le `fit()` permet de voir l'évolution du modèle et de ses performances durant l'entrainement et donc d'arrêter l'entrainement si les choses ne vont pas bien\n",
    "\n",
    "\n",
    "- Le tableau de bord **Scalars** montre comment la perte et les paramètres changent à chaque époque. Vous pouvez également l'utiliser pour suivre la vitesse d'entraînement, le taux d'apprentissage et d'autres valeurs scalaires.\n",
    "- Le tableau de bord **Graphs** vous permet de visualiser votre modèle. Dans ce cas, le graphique Keras des couches s'affiche, ce qui peut vous aider à vous assurer qu'il est correctement construit.\n",
    "- Les tableaux de bord **Histograms** montrent la distribution d'un Tensor au fil du temps. Cela peut être utile pour visualiser les poids et les biais et vérifier qu'ils changent de manière attendue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5v_ebdmedTfD"
   },
   "outputs": [],
   "source": [
    "# %tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ovvIU3k69Xzn"
   },
   "source": [
    "fit le modele en rajoutant le callbak vers tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On entraîne le modèle et on enregistre l'historique d'apprentissage.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MdEnohurS8bH"
   },
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "            train_generator,\n",
    "            epochs=5,\n",
    "            validation_data=validation_generator,\n",
    "            verbose=2,\n",
    "            callbacks=[tensorboard_callback]\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On évalue les performances finales sur le jeu de validation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PMZywOTlTBiK"
   },
   "outputs": [],
   "source": [
    "test_loss, test_accuracy = model.evaluate(validation_generator, steps=validation_generator.samples // validation_generator.batch_size)\n",
    "print(f'Test loss: {test_loss}')\n",
    "print(f'Test accuracy: {test_accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On évalue les performances finales sur le jeu de validation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZRjQjW0rcbQN"
   },
   "outputs": [],
   "source": [
    "train_loss, train_accuracy = model.evaluate(train_generator, steps=train_generator.samples // train_generator.batch_size)\n",
    "print(f'Train loss: {train_loss}')\n",
    "print(f'Train accuracy: {train_accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On exécute cette étape du pipeline d'entraînement.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QvBi3ZlzfN7y"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}