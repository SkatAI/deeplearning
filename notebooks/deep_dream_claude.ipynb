{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Ouvrir sur Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/SkatAI/deeplearning/blob/master/notebooks/deep_dream_claude.ipynb)\n",
    "\n",
    "# DeepDream ‚Äî Quand les r√©seaux de neurones hallucinent\n",
    "\n",
    "**Deep Learning par la pratique ‚Äî Alexis Perrier**\n",
    "\n",
    "---\n",
    "\n",
    "## Qu'est-ce que DeepDream ?\n",
    "\n",
    "En 2015, des ing√©nieurs de Google se sont pos√© une question simple : **que \"voit\" un r√©seau de neurones quand il regarde une image ?**\n",
    "\n",
    "Pour r√©pondre, ils ont invers√© le processus habituel :\n",
    "\n",
    "| Processus normal | DeepDream |\n",
    "|---|---|\n",
    "| On modifie les **poids** du r√©seau pour qu'il reconnaisse mieux les images | On modifie **l'image elle-m√™me** pour amplifier ce que le r√©seau y \"voit\" d√©j√† |\n",
    "| Descente de gradient sur les poids | **Mont√©e** de gradient sur les pixels |\n",
    "| Le r√©seau apprend | Le r√©seau **hallucine** |\n",
    "\n",
    "Le r√©sultat : des images psych√©d√©liques o√π le r√©seau projette ses propres patterns ‚Äî yeux, visages d'animaux, textures fractales ‚Äî sur n'importe quelle photo.\n",
    "\n",
    "### Pourquoi c'est int√©ressant ?\n",
    "\n",
    "- C'est une fen√™tre sur ce que les couches du r√©seau ont **r√©ellement appris**\n",
    "- Les couches basses voient des **textures et motifs g√©om√©triques**\n",
    "- Les couches hautes voient des **formes complexes** (yeux, museaux, plumes)\n",
    "- C'est aussi devenu un **outil artistique** √† part enti√®re\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## √âtape 0 ‚Äî Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.applications import inception_v3\n",
    "import IPython.display as display\n",
    "from PIL import Image\n",
    "import time\n",
    "\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"GPU disponible: {tf.config.list_physical_devices('GPU')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## √âtape 1 ‚Äî Charger une image de d√©part\n",
    "\n",
    "On commence avec une image riche en textures et en d√©tails ‚Äî c'est ce qui donne les meilleurs r√©sultats avec DeepDream."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# T√©l√©charger une image spectaculaire\n",
    "url = 'https://storage.googleapis.com/download.tensorflow.org/example_images/YellowLabradorLooking_new.jpg'\n",
    "image_path = keras.utils.get_file('labrador.jpg', url)\n",
    "\n",
    "# Fonctions utilitaires pour charger et afficher les images\n",
    "def load_image(path, max_dim=512):\n",
    "    \"\"\"Charge une image et la redimensionne.\"\"\"\n",
    "    img = Image.open(path)\n",
    "    img.thumbnail((max_dim, max_dim))\n",
    "    img = np.array(img)\n",
    "    return img\n",
    "\n",
    "def show_image(img, title=''):\n",
    "    \"\"\"Affiche une image.\"\"\"\n",
    "    if isinstance(img, tf.Tensor):\n",
    "        img = img.numpy()\n",
    "    img = np.clip(img, 0, 255).astype(np.uint8)\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    if title:\n",
    "        plt.title(title, fontsize=16)\n",
    "    plt.show()\n",
    "\n",
    "# Charger et afficher\n",
    "original_img = load_image(image_path)\n",
    "show_image(original_img, 'Image originale')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## √âtape 2 ‚Äî Charger le mod√®le InceptionV3\n",
    "\n",
    "DeepDream a √©t√© invent√© avec le r√©seau **InceptionV3** de Google ‚Äî c'est le mod√®le classique pour cet effet.\n",
    "\n",
    "Ce r√©seau a √©t√© entra√Æn√© sur ImageNet (1,4 million d'images, 1000 cat√©gories). Il a appris √† reconna√Ætre des textures, des formes, des objets, des animaux.\n",
    "\n",
    "On ne va pas l'utiliser pour classifier des images. On va regarder **√† l'int√©rieur** pour voir ce que chaque couche a appris."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger InceptionV3 pr√©-entra√Æn√©\n",
    "base_model = inception_v3.InceptionV3(include_top=False, weights='imagenet')\n",
    "\n",
    "# Lister quelques couches int√©ressantes\n",
    "print(f\"Nombre total de couches : {len(base_model.layers)}\\n\")\n",
    "print(\"Quelques couches disponibles :\")\n",
    "for layer in base_model.layers:\n",
    "    if 'mixed' in layer.name:\n",
    "        print(f\"  - {layer.name:20s}  ‚Üí  output shape: {layer.output.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ü§ñ GEMINI\n",
    "\n",
    "Demandez √† Gemini :\n",
    "\n",
    "> *\"Qu'est-ce que le r√©seau InceptionV3 ? Pourquoi s'appelle-t-il Inception ? Quelle est la diff√©rence entre les couches 'mixed0' (d√©but du r√©seau) et 'mixed10' (fin du r√©seau) en termes de ce qu'elles d√©tectent ?\"*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## √âtape 3 ‚Äî Comprendre le principe : gradient ascent\n",
    "\n",
    "Quand on entra√Æne un r√©seau normalement, on fait de la **descente de gradient** : on modifie les poids pour **minimiser** une erreur.\n",
    "\n",
    "Avec DeepDream, on fait l'inverse ‚Äî de la **mont√©e de gradient** (gradient ascent) :\n",
    "- On choisit une couche du r√©seau\n",
    "- On calcule les activations de cette couche pour notre image\n",
    "- On modifie **les pixels de l'image** (pas les poids !) pour **maximiser** ces activations\n",
    "- Le r√©seau amplifie ce qu'il \"voit\" d√©j√† dans l'image\n",
    "\n",
    "C'est comme demander au r√©seau : *\"Qu'est-ce que tu vois ? Montre-le-moi encore plus fort !\"*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 ‚Äî Choisir les couches\n",
    "\n",
    "Le choix des couches d√©termine le type d'hallucinations :\n",
    "- **Couches basses** (mixed0, mixed1) ‚Üí textures, motifs g√©om√©triques, ondulations\n",
    "- **Couches interm√©diaires** (mixed3, mixed4) ‚Üí formes r√©p√©titives, yeux, spirales\n",
    "- **Couches hautes** (mixed7, mixed10) ‚Üí objets complets, visages d'animaux, structures complexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On choisit les couches dont on veut amplifier les activations\n",
    "# Chaque couche a un poids qui contr√¥le son influence\n",
    "\n",
    "dream_layers = {\n",
    "    'mixed3': 0.5,\n",
    "    'mixed5': 1.5,\n",
    "}\n",
    "\n",
    "# Cr√©er le mod√®le DeepDream\n",
    "outputs = [base_model.get_layer(name).output for name in dream_layers]\n",
    "dream_model = keras.Model(inputs=base_model.input, outputs=outputs)\n",
    "\n",
    "print(\"Couches s√©lectionn√©es pour le r√™ve :\")\n",
    "for name, weight in dream_layers.items():\n",
    "    print(f\"  - {name} (poids: {weight})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 ‚Äî La fonction de perte et le gradient ascent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss(image, model, layer_weights):\n",
    "    \"\"\"Calcule la perte = somme pond√©r√©e des activations des couches choisies.\n",
    "    Plus la perte est √©lev√©e, plus le r√©seau 'voit' des choses dans l'image.\"\"\"\n",
    "    # Pr√©-traitement pour InceptionV3\n",
    "    img = inception_v3.preprocess_input(image)\n",
    "    # Obtenir les activations des couches choisies\n",
    "    activations = model(img)\n",
    "    if not isinstance(activations, list):\n",
    "        activations = [activations]\n",
    "\n",
    "    losses = []\n",
    "    weights = list(layer_weights.values())\n",
    "    for activation, weight in zip(activations, weights):\n",
    "        # La perte = la moyenne des activations √ó le poids\n",
    "        loss = tf.reduce_mean(activation) * weight\n",
    "        losses.append(loss)\n",
    "\n",
    "    return tf.reduce_sum(losses)\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def deepdream_step(image, model, layer_weights, step_size):\n",
    "    \"\"\"Une √©tape de gradient ascent : modifier l'image pour amplifier les activations.\"\"\"\n",
    "    with tf.GradientTape() as tape:\n",
    "        tape.watch(image)\n",
    "        loss = compute_loss(image, model, layer_weights)\n",
    "\n",
    "    # Calculer le gradient par rapport aux pixels de l'image\n",
    "    gradients = tape.gradient(loss, image)\n",
    "\n",
    "    # Normaliser les gradients\n",
    "    gradients /= tf.math.reduce_std(gradients) + 1e-8\n",
    "\n",
    "    # MONT√âE de gradient : on AJOUTE le gradient (au lieu de le soustraire)\n",
    "    image = image + gradients * step_size\n",
    "\n",
    "    # Garder les valeurs de pixels dans une plage raisonnable\n",
    "    image = tf.clip_by_value(image, -1, 1)\n",
    "\n",
    "    return image, loss\n",
    "\n",
    "print(\"Fonctions DeepDream pr√™tes !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚ùì QUESTION\n",
    "\n",
    "Regardez la ligne `image = image + gradients * step_size` dans le code ci-dessus.\n",
    "\n",
    "- Dans l'entra√Ænement classique d'un r√©seau, on √©crirait `weights = weights **-** learning_rate * gradients`. Quelle est la diff√©rence ?\n",
    "- Pourquoi ajoute-t-on le gradient au lieu de le soustraire ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*(votre r√©ponse ici)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## √âtape 4 ‚Äî Premier r√™ve !\n",
    "\n",
    "On lance DeepDream sur notre image. On va voir le r√©seau projeter ses hallucinations sur la photo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_deepdream_simple(image, model, layer_weights, steps=100, step_size=0.01):\n",
    "    \"\"\"Lance DeepDream sur une image pendant un certain nombre d'√©tapes.\"\"\"\n",
    "    # Convertir en float32 et ajouter la dimension batch\n",
    "    img = tf.constant(np.array(image), dtype=tf.float32)\n",
    "    img = tf.expand_dims(img, axis=0)\n",
    "\n",
    "    for step in range(steps):\n",
    "        img, loss = deepdream_step(img, model, layer_weights, step_size)\n",
    "        if step % 25 == 0:\n",
    "            print(f\"  √âtape {step:3d}, perte = {loss.numpy():.2f}\")\n",
    "\n",
    "    # Retirer la dimension batch et remettre en [0, 255]\n",
    "    result = img[0].numpy()\n",
    "    result = ((result + 1) / 2 * 255)  # de [-1,1] vers [0,255]\n",
    "    result = np.clip(result, 0, 255).astype(np.uint8)\n",
    "    return result\n",
    "\n",
    "\n",
    "print(\"üåÄ DeepDream en cours...\")\n",
    "start_time = time.time()\n",
    "\n",
    "dream_img = run_deepdream_simple(\n",
    "    original_img,\n",
    "    dream_model,\n",
    "    dream_layers,\n",
    "    steps=100,\n",
    "    step_size=0.01\n",
    ")\n",
    "\n",
    "elapsed = time.time() - start_time\n",
    "print(f\"\\n‚úÖ Termin√© en {elapsed:.1f} secondes\")\n",
    "\n",
    "# Afficher c√¥te √† c√¥te\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 8))\n",
    "ax1.imshow(original_img)\n",
    "ax1.set_title('Image originale', fontsize=14)\n",
    "ax1.axis('off')\n",
    "ax2.imshow(dream_img)\n",
    "ax2.set_title('DeepDream', fontsize=14)\n",
    "ax2.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚ùì QUESTION\n",
    "\n",
    "- Quels patterns voyez-vous appara√Ætre dans l'image ?\n",
    "- Reconnaissez-vous des formes d'animaux, des yeux, des textures ?\n",
    "- Pourquoi le r√©seau projette-t-il ces formes en particulier ? (indice : sur quel dataset a-t-il √©t√© entra√Æn√© ?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*(vos observations ici)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## √âtape 5 ‚Äî Explorer les couches : que voit le r√©seau √† chaque profondeur ?\n",
    "\n",
    "C'est la partie la plus r√©v√©latrice. On va appliquer DeepDream avec **diff√©rentes couches** pour voir comment les features √©voluent dans le r√©seau."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tester 4 configurations de couches diff√©rentes\n",
    "experiments = {\n",
    "    'Couches basses\\n(textures)': {'mixed0': 1.0, 'mixed1': 1.0},\n",
    "    'Couches moyennes\\n(motifs)': {'mixed3': 1.0, 'mixed4': 1.0},\n",
    "    'Couches hautes\\n(formes)': {'mixed5': 1.0, 'mixed7': 1.0},\n",
    "    'Couches tr√®s hautes\\n(objets)': {'mixed8': 1.0, 'mixed10': 1.0},\n",
    "}\n",
    "\n",
    "fig, axes = plt.subplots(1, 4, figsize=(24, 6))\n",
    "\n",
    "for ax, (title, layers_config) in zip(axes, experiments.items()):\n",
    "    print(f\"\\nüåÄ {title.replace(chr(10), ' ')}...\")\n",
    "\n",
    "    # Cr√©er le mod√®le pour ces couches\n",
    "    layer_outputs = [base_model.get_layer(name).output for name in layers_config]\n",
    "    model = keras.Model(inputs=base_model.input, outputs=layer_outputs)\n",
    "\n",
    "    # Lancer DeepDream\n",
    "    result = run_deepdream_simple(\n",
    "        original_img, model, layers_config,\n",
    "        steps=80, step_size=0.01\n",
    "    )\n",
    "\n",
    "    ax.imshow(result)\n",
    "    ax.set_title(title, fontsize=13)\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.suptitle('DeepDream ‚Äî Impact de la profondeur des couches', fontsize=16, y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚ùì QUESTION\n",
    "\n",
    "Comparez les 4 images :\n",
    "- **Couches basses** : quel type de patterns voyez-vous ? (textures ? motifs g√©om√©triques ?)\n",
    "- **Couches hautes** : les patterns sont-ils plus figuratifs ? Reconnaissez-vous des formes ?\n",
    "- Que nous apprend cette progression sur la fa√ßon dont un r√©seau de neurones \"comprend\" une image ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*(vos observations ici)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## √âtape 6 ‚Äî DeepDream multi-scale (octaves)\n",
    "\n",
    "La version basique produit des r√©sultats un peu flous. La technique des **octaves** donne des r√©sultats bien plus nets et spectaculaires.\n",
    "\n",
    "Le principe :\n",
    "1. R√©duire l'image\n",
    "2. Appliquer DeepDream sur la petite version\n",
    "3. Agrandir le r√©sultat\n",
    "4. Ajouter les d√©tails perdus\n",
    "5. R√©appliquer DeepDream\n",
    "6. R√©p√©ter √† plusieurs √©chelles\n",
    "\n",
    "Chaque passage √† une √©chelle sup√©rieure s'appelle une **octave** (comme en musique)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_deepdream_octaves(image, model, layer_weights,\n",
    "                          steps_per_octave=50, step_size=0.01,\n",
    "                          num_octaves=3, octave_scale=1.3):\n",
    "    \"\"\"DeepDream multi-scale avec octaves pour des r√©sultats plus nets.\"\"\"\n",
    "\n",
    "    img = tf.constant(np.array(image), dtype=tf.float32)\n",
    "    img = tf.expand_dims(img, axis=0)\n",
    "\n",
    "    original_shape = tf.shape(img)[1:3]\n",
    "\n",
    "    for octave in range(num_octaves):\n",
    "        # Calculer la taille pour cette octave\n",
    "        scale = octave_scale ** (num_octaves - 1 - octave)\n",
    "        new_size = tf.cast(tf.cast(original_shape, tf.float32) / scale, tf.int32)\n",
    "\n",
    "        # Redimensionner l'image\n",
    "        img = tf.image.resize(img, new_size)\n",
    "\n",
    "        print(f\"  Octave {octave + 1}/{num_octaves} ‚Äî taille: {new_size[0].numpy()}x{new_size[1].numpy()}\")\n",
    "\n",
    "        # Appliquer DeepDream √† cette √©chelle\n",
    "        for step in range(steps_per_octave):\n",
    "            img, loss = deepdream_step(img, model, layer_weights, step_size)\n",
    "\n",
    "        print(f\"    ‚Üí perte = {loss.numpy():.2f}\")\n",
    "\n",
    "    # Remettre √† la taille originale\n",
    "    img = tf.image.resize(img, original_shape)\n",
    "\n",
    "    # Post-traitement\n",
    "    result = img[0].numpy()\n",
    "    result = ((result + 1) / 2 * 255)\n",
    "    result = np.clip(result, 0, 255).astype(np.uint8)\n",
    "    return result\n",
    "\n",
    "\n",
    "# Recr√©er le mod√®le avec les couches de r√™ve\n",
    "dream_layers_octave = {'mixed3': 0.5, 'mixed5': 1.5}\n",
    "outputs_octave = [base_model.get_layer(name).output for name in dream_layers_octave]\n",
    "dream_model_octave = keras.Model(inputs=base_model.input, outputs=outputs_octave)\n",
    "\n",
    "print(\"üåÄ DeepDream multi-scale (octaves) en cours...\")\n",
    "start_time = time.time()\n",
    "\n",
    "dream_octave = run_deepdream_octaves(\n",
    "    original_img,\n",
    "    dream_model_octave,\n",
    "    dream_layers_octave,\n",
    "    steps_per_octave=50,\n",
    "    step_size=0.01,\n",
    "    num_octaves=3,\n",
    "    octave_scale=1.3\n",
    ")\n",
    "\n",
    "elapsed = time.time() - start_time\n",
    "print(f\"\\n‚úÖ Termin√© en {elapsed:.1f} secondes\")\n",
    "\n",
    "# Comparer les 3 versions\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(20, 7))\n",
    "ax1.imshow(original_img)\n",
    "ax1.set_title('Originale', fontsize=14)\n",
    "ax1.axis('off')\n",
    "ax2.imshow(dream_img)\n",
    "ax2.set_title('DeepDream simple', fontsize=14)\n",
    "ax2.axis('off')\n",
    "ax3.imshow(dream_octave)\n",
    "ax3.set_title('DeepDream octaves', fontsize=14)\n",
    "ax3.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚ùì QUESTION\n",
    "\n",
    "Comparez les versions \"simple\" et \"octaves\" :\n",
    "- Laquelle produit des d√©tails plus fins ?\n",
    "- La version octaves contient-elle des patterns √† diff√©rentes √©chelles ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*(vos observations ici)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## √âtape 7 ‚Äî Exp√©rimenter\n",
    "\n",
    "### 7.1 ‚Äî Modifier l'intensit√© du r√™ve\n",
    "\n",
    "Le param√®tre `step_size` contr√¥le l'intensit√© de l'effet. Plus il est √©lev√©, plus les hallucinations sont prononc√©es."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intensities = [0.005, 0.01, 0.03]\n",
    "labels = ['Subtil', 'Mod√©r√©', 'Intense']\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(20, 7))\n",
    "\n",
    "for ax, step_size, label in zip(axes, intensities, labels):\n",
    "    print(f\"\\nüåÄ {label} (step_size={step_size})...\")\n",
    "    result = run_deepdream_simple(\n",
    "        original_img, dream_model, dream_layers,\n",
    "        steps=80, step_size=step_size\n",
    "    )\n",
    "    ax.imshow(result)\n",
    "    ax.set_title(f'{label}\\n(step_size={step_size})', fontsize=13)\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.suptitle(\"Impact de l'intensit√© (step_size)\", fontsize=16, y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ü§ñ GEMINI ‚Äî Exp√©rimenter avec d'autres combinaisons\n",
    "\n",
    "Demandez √† Gemini :\n",
    "\n",
    "> *\"Modifie le dictionnaire `dream_layers` pour utiliser uniquement la couche 'mixed7' avec un poids de 2.0. Relance DeepDream avec 100 √©tapes et step_size=0.01. Affiche le r√©sultat √† c√¥t√© de l'original.\"*\n",
    "\n",
    "Puis essayez d'autres combinaisons et demandez :\n",
    "\n",
    "> *\"Quelles couches d'InceptionV3 produisent les effets les plus psych√©d√©liques ? Pourquoi les couches profondes g√©n√®rent-elles des formes d'animaux ?\"*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VOTRE CODE G√âN√âR√â PAR GEMINI ICI\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## √âtape 8 ‚Äî Testez avec vos propres images !\n",
    "\n",
    "Uploadez n'importe quelle image et voyez ce que le r√©seau y hallucine.\n",
    "\n",
    "**Suggestions** :\n",
    "- une de vos cr√©ations 3D / Blender\n",
    "- un paysage, un b√¢timent, un portrait\n",
    "- une texture, un motif abstrait\n",
    "- une photo du quotidien\n",
    "\n",
    "Les images avec beaucoup de textures et de d√©tails donnent les r√©sultats les plus spectaculaires."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "\n",
    "print(\"Uploadez une image :\")\n",
    "uploaded = files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in uploaded.keys():\n",
    "    print(f\"\\nüì∑ Image : {filename}\")\n",
    "\n",
    "    # Charger l'image\n",
    "    my_img = load_image(filename, max_dim=512)\n",
    "\n",
    "    # Lancer DeepDream avec octaves\n",
    "    my_layers = {'mixed3': 0.5, 'mixed5': 1.5}\n",
    "    my_outputs = [base_model.get_layer(name).output for name in my_layers]\n",
    "    my_model = keras.Model(inputs=base_model.input, outputs=my_outputs)\n",
    "\n",
    "    print(\"üåÄ DeepDream en cours...\")\n",
    "    my_dream = run_deepdream_octaves(\n",
    "        my_img, my_model, my_layers,\n",
    "        steps_per_octave=50, step_size=0.01,\n",
    "        num_octaves=3, octave_scale=1.3\n",
    "    )\n",
    "\n",
    "    # Afficher\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 8))\n",
    "    ax1.imshow(my_img)\n",
    "    ax1.set_title('Votre image', fontsize=14)\n",
    "    ax1.axis('off')\n",
    "    ax2.imshow(my_dream)\n",
    "    ax2.set_title('DeepDream', fontsize=14)\n",
    "    ax2.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ü§ñ GEMINI ‚Äî Aller plus loin avec vos images\n",
    "\n",
    "Demandez √† Gemini :\n",
    "\n",
    "> *\"Modifie le code pour tester mon image avec 3 configurations de couches diff√©rentes c√¥te √† c√¥te : couches basses (mixed0, mixed1), couches moyennes (mixed3, mixed5), couches hautes (mixed8, mixed10). Affiche les 3 r√©sultats dans une grille.\"*\n",
    "\n",
    "Ou bien :\n",
    "\n",
    "> *\"Ajoute le code pour sauvegarder l'image DeepDream en haute r√©solution dans un fichier PNG.\"*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VOTRE CODE G√âN√âR√â PAR GEMINI ICI\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## √âtape 9 ‚Äî Synth√®se\n",
    "\n",
    "### Ce qu'on a appris\n",
    "\n",
    "| Concept | Ce qu'on a vu |\n",
    "|---|---|\n",
    "| **Gradient ascent** | Au lieu de minimiser une erreur, on maximise les activations ‚Üí le r√©seau amplifie ce qu'il \"voit\" |\n",
    "| **Hi√©rarchie des features** | Les couches basses d√©tectent des textures, les couches hautes des objets complexes |\n",
    "| **Biais du dataset** | Le r√©seau hallucine des animaux parce qu'il a √©t√© entra√Æn√© sur ImageNet (beaucoup d'animaux) |\n",
    "| **Octaves** | Travailler √† plusieurs √©chelles produit des d√©tails plus fins et plus nets |\n",
    "\n",
    "### ‚ùì QUESTIONS FINALES\n",
    "\n",
    "1. Si on entra√Ænait le r√©seau sur un dataset de b√¢timents au lieu d'ImageNet, que verrait-on appara√Ætre dans les r√™ves ?\n",
    "\n",
    "2. DeepDream est souvent pr√©sent√© comme un outil artistique. Mais en quoi est-ce aussi un outil de **compr√©hension** des r√©seaux de neurones ?\n",
    "\n",
    "3. Comment pourriez-vous int√©grer DeepDream dans un projet cr√©atif (3D, design, art g√©n√©ratif) ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*(vos r√©ponses ici)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Pour aller plus loin (optionnel)\n",
    "\n",
    "Quelques pistes d'exploration avec Gemini :\n",
    "\n",
    "- **Cr√©er une animation** : appliquer DeepDream de mani√®re it√©rative (chaque output devient l'input suivant) et assembler les frames en GIF\n",
    "- **Style transfer** : combiner DeepDream avec le Neural Style Transfer pour appliquer le style d'un tableau sur une photo\n",
    "- **R√™ve progressif** : augmenter graduellement le step_size pour montrer l'image qui \"plonge\" dans le r√™ve\n",
    "- **Zoomer dans le r√™ve** : appliquer DeepDream + zoom au centre √† chaque it√©ration (effet de plong√©e infinie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VOTRE EXPLORATION ICI\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  },
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}