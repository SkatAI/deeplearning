{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/SkatAI/skatai_deeplearning/blob/master/notebooks/les_tenseurs.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Executer dans Google Colab</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/SkatAI/skatai_deeplearning/blob/master/notebooks/les_tenseurs.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />sur GitHub</a>\n",
        "  </td>\n",
        "</table>"
      ],
      "metadata": {
        "id": "fvpo9LFVGAni"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mulit Layer Perceptron avec scikit-learn\n",
        "\n",
        "Dans ce notebook nous allons entrainer un modele de MLP de scikit-learn sur la base du dataset MNIST\n",
        "\n",
        "- MLPClassifier : https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html\n",
        "- MNIST : http://yann.lecun.com/exdb/mnist/\n",
        "- MNIST sur openml : https://www.openml.org/search?type=data&sort=runs&id=554&status=active\n",
        "\n",
        "L'objectif est d'observer l'influence des paramètres et de l'architecture sur\n",
        "- les performances du modele\n",
        "- l'overfitting\n",
        "\n",
        "Nous allons démarrer avec un model simple puis travailler sur\n",
        "- le learning rate\n",
        "- l'architecture : nombre de couches, nombre de noeuds\n",
        "- les epochs\n",
        "- la régularisation L2 et L1"
      ],
      "metadata": {
        "id": "7BeTYmJyGEHt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EII31aueF7MN"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neural_network import MLPClassifier\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# charger le jeu de données\n",
        "\n",
        "X, y = fetch_openml(\"mnist_784\", version=1, return_X_y=True, as_frame=False)\n",
        "\n"
      ],
      "metadata": {
        "id": "gejopDToG920"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Chaque image est un array de 3 valeurs int entre 0 et 255\n",
        "\n",
        "On les normalise pour que les valeurs soient des floats entre 0 et 1"
      ],
      "metadata": {
        "id": "qOV-GzVNxWBF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# normalisation\n",
        "X = X / 255.0\n"
      ],
      "metadata": {
        "id": "d1_2_Z3hI5YP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split data into train partition and test partition\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0, test_size=0.7)\n"
      ],
      "metadata": {
        "id": "rnY41JteIVzn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# definir le model avec 1 couche cachée et 40 noeud internes\n",
        "# https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html\n",
        "\n",
        "mlp = MLPClassifier(\n",
        "    hidden_layer_sizes=(20,),\n",
        "    max_iter=20,\n",
        "    alpha=0,\n",
        "    solver=\"sgd\",\n",
        "    verbose=10,\n",
        "    random_state=1,\n",
        "    early_stopping = False,\n",
        "    learning_rate_init=0.2,\n",
        ")\n"
      ],
      "metadata": {
        "id": "cjAJ6sXFIjIF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mlp.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "-JpqBVJsIl77"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# score = mean accuracy\n",
        "print(\"Training set score: %f\" % mlp.score(X_train, y_train))\n",
        "print(\"Test set score: %f\" % mlp.score(X_test, y_test))\n"
      ],
      "metadata": {
        "id": "Q4AykUMMJCd3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(mlp.loss_curve_)\n",
        "plt.grid()\n"
      ],
      "metadata": {
        "id": "_ipkNta7Jo_z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Voir les coefficients de la couche interne"
      ],
      "metadata": {
        "id": "OyxW0JvdIt6-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axes = plt.subplots(4, 4)\n",
        "# use global min / max to ensure all weights are shown on the same scale\n",
        "vmin, vmax = mlp.coefs_[0].min(), mlp.coefs_[0].max()\n",
        "for coef, ax in zip(mlp.coefs_[0].T, axes.ravel()):\n",
        "    ax.matshow(coef.reshape(28, 28), cmap=plt.cm.gray, vmin=0.5 * vmin, vmax=0.5 * vmax)\n",
        "    ax.set_xticks(())\n",
        "    ax.set_yticks(())\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "BS6_yOp4InrU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# A vous\n",
        "\n",
        "Qu'observe t on quand\n",
        "- on augmente le nombre d'epoch (max_iter)\n",
        "- on augmente la taille de la couche cachée\n",
        "- on rajoute une autre couche de meme taille\n",
        "- on ne garde qu'une couche mais de taille plus réduite\n",
        "\n",
        "Creer de l'overfit avec un modele trop complexe :\n",
        "\n",
        "- augmenter la taille et le nombre de couches\n",
        "- reduire le learning rate\n",
        "- mettre alpha à 0\n",
        "\n",
        "Puis une fois que l'overfit apparaît essayer de le réduire en jouant avec\n",
        "- le alpha (L2)\n",
        "- le batch size"
      ],
      "metadata": {
        "id": "KHFY7GltKCoZ"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Bo3zMUUTzdku"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}