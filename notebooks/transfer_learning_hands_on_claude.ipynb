{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning ‚Äî Atelier pratique\n",
    "\n",
    "**Deep Learning par la pratique ‚Äî Alexis Perrier**\n",
    "\n",
    "---\n",
    "\n",
    "## Objectifs de cet atelier\n",
    "\n",
    "1. **Comprendre le Transfer Learning** : pourquoi on ne part jamais de z√©ro en deep learning\n",
    "2. **Travailler avec l'IA** : utiliser Gemini pour g√©n√©rer, lire et comprendre du code\n",
    "\n",
    "## Comment utiliser ce notebook\n",
    "\n",
    "- Les cellules avec du code pr√©-√©crit : **lisez, ex√©cutez, observez**\n",
    "- Les cellules marqu√©es ü§ñ **GEMINI** : demandez √† Gemini de g√©n√©rer le code, puis lisez-le et demandez-lui de vous l'expliquer\n",
    "- Les cellules marqu√©es ‚ùì **QUESTION** : r√©pondez en observant les r√©sultats\n",
    "\n",
    "**Utiliser l'IA pour coder n'est pas tricher ‚Äî c'est la m√©thode de travail.**\n",
    "Votre valeur n'est pas de taper du code, c'est de savoir quoi demander, comprendre ce qu'on vous donne, et juger si le r√©sultat est bon.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## √âtape 0 ‚Äî Setup et exploration des donn√©es\n",
    "\n",
    "On travaille avec le dataset **Cats vs Dogs** : des photos de chats et de chiens.\n",
    "Notre objectif : construire un mod√®le qui distingue les deux.\n",
    "\n",
    "### 0.1 ‚Äî Installer et importer les librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"GPU disponible: {tf.config.list_physical_devices('GPU')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.2 ‚Äî T√©l√©charger le dataset\n",
    "\n",
    "On utilise un sous-ensemble du dataset Cats vs Dogs (environ 3000 images).\n",
    "C'est suffisant pour notre exp√©rimentation et √ßa reste rapide sur Colab free tier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# T√©l√©charger le dataset\n",
    "!wget --no-check-certificate \\\n",
    "    https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip \\\n",
    "    -O /content/catsdogs.zip\n",
    "\n",
    "import zipfile\n",
    "with zipfile.ZipFile('/content/catsdogs.zip', 'r') as zip_ref:\n",
    "    zip_ref.extractall('/content/')\n",
    "\n",
    "base_dir = '/content/cats_and_dogs_filtered/'\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "validation_dir = os.path.join(base_dir, 'validation')\n",
    "\n",
    "print(\"Dataset t√©l√©charg√© !\")\n",
    "print(f\"Images d'entra√Ænement (chats) : {len(os.listdir(os.path.join(train_dir, 'cats')))}\")\n",
    "print(f\"Images d'entra√Ænement (chiens) : {len(os.listdir(os.path.join(train_dir, 'dogs')))}\")\n",
    "print(f\"Images de validation (chats) : {len(os.listdir(os.path.join(validation_dir, 'cats')))}\")\n",
    "print(f\"Images de validation (chiens) : {len(os.listdir(os.path.join(validation_dir, 'dogs')))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.3 ‚Äî Charger les images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = (160, 160)\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "train_dataset = keras.utils.image_dataset_from_directory(\n",
    "    train_dir,\n",
    "    shuffle=True,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    image_size=IMG_SIZE\n",
    ")\n",
    "\n",
    "val_dataset = keras.utils.image_dataset_from_directory(\n",
    "    validation_dir,\n",
    "    shuffle=True,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    image_size=IMG_SIZE\n",
    ")\n",
    "\n",
    "class_names = train_dataset.class_names\n",
    "print(f\"Classes : {class_names}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ü§ñ GEMINI ‚Äî Visualiser les donn√©es\n",
    "\n",
    "Demandez √† Gemini :\n",
    "\n",
    "> *\"G√©n√®re du code pour afficher une grille de 12 images al√©atoires du dataset `train_dataset` avec leurs labels ('cats' ou 'dogs') en titre. Utilise matplotlib avec une grille 3x4.\"*\n",
    "\n",
    "Ensuite, demandez-lui :\n",
    "\n",
    "> *\"Explique-moi ce que fait chaque ligne de ce code.\"*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VOTRE CODE G√âN√âR√â PAR GEMINI ICI\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚ùì QUESTION\n",
    "\n",
    "En observant les images :\n",
    "- Les images sont-elles toutes de la m√™me taille ? de la m√™me qualit√© ?\n",
    "- Y a-t-il des images \"difficiles\" (animal de dos, mal cadr√©, plusieurs animaux) ?\n",
    "- Pensez-vous qu'un humain ferait 100% de bonnes r√©ponses sur ce dataset ?\n",
    "\n",
    "*√âcrivez vos observations ci-dessous :*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*(vos observations ici)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.4 ‚Äî Optimiser le chargement des donn√©es\n",
    "\n",
    "Cette cellule optimise le chargement des images pour acc√©l√©rer l'entra√Ænement.\n",
    "`prefetch` pr√©pare le batch suivant pendant que le GPU traite le batch courant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "train_dataset = train_dataset.prefetch(buffer_size=AUTOTUNE)\n",
    "val_dataset = val_dataset.prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## √âtape 1 ‚Äî Baseline : un petit CNN entra√Æn√© from scratch\n",
    "\n",
    "Avant d'utiliser le Transfer Learning, on va d'abord essayer de construire un mod√®le **√† partir de z√©ro** (from scratch). C'est notre **baseline** ‚Äî le point de r√©f√©rence.\n",
    "\n",
    "On construit un petit CNN (Convolutional Neural Network) avec 3 couches de convolution.\n",
    "\n",
    "### 1.1 ‚Äî Normaliser les pixels\n",
    "\n",
    "Les pixels d'une image ont des valeurs entre 0 et 255. On les ram√®ne entre 0 et 1 pour faciliter l'entra√Ænement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalization_layer = layers.Rescaling(1./255)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 ‚Äî Construire un petit CNN from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scratch_model = keras.Sequential([\n",
    "    # Normalisation des pixels (0-255 ‚Üí 0-1)\n",
    "    normalization_layer,\n",
    "\n",
    "    # Bloc 1 : d√©tecter des features simples (bords, textures)\n",
    "    layers.Conv2D(16, (3, 3), activation='relu', input_shape=(160, 160, 3)),\n",
    "    layers.MaxPooling2D(2, 2),\n",
    "\n",
    "    # Bloc 2 : d√©tecter des features plus complexes (formes)\n",
    "    layers.Conv2D(32, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D(2, 2),\n",
    "\n",
    "    # Bloc 3 : features encore plus abstraites\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D(2, 2),\n",
    "\n",
    "    # Classification\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(1, activation='sigmoid')  # 1 sortie : chat (0) ou chien (1)\n",
    "])\n",
    "\n",
    "scratch_model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "scratch_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ü§ñ GEMINI ‚Äî Comprendre l'architecture\n",
    "\n",
    "Demandez √† Gemini :\n",
    "\n",
    "> *\"Explique-moi le `model.summary()` ci-dessus. Que signifient les colonnes Output Shape et Param # ? Combien de param√®tres ce mod√®le a-t-il au total ?\"*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 ‚Äî Entra√Æner le mod√®le from scratch\n",
    "\n",
    "On entra√Æne pendant 10 √©poques. Une √©poque = le mod√®le a vu toutes les images une fois."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Entra√Ænement du mod√®le from scratch...\")\n",
    "print(\"(cela prend environ 2-3 minutes)\")\n",
    "\n",
    "history_scratch = scratch_model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=val_dataset,\n",
    "    epochs=10\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 ‚Äî Visualiser les r√©sultats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training(history, title):\n",
    "    \"\"\"Affiche les courbes d'accuracy et de loss pour train et validation.\"\"\"\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "    # Accuracy\n",
    "    ax1.plot(history.history['accuracy'], label='Train', linewidth=2)\n",
    "    ax1.plot(history.history['val_accuracy'], label='Validation', linewidth=2)\n",
    "    ax1.set_title(f'{title} ‚Äî Accuracy')\n",
    "    ax1.set_xlabel('√âpoque')\n",
    "    ax1.set_ylabel('Accuracy')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    ax1.set_ylim([0.4, 1.0])\n",
    "\n",
    "    # Loss\n",
    "    ax2.plot(history.history['loss'], label='Train', linewidth=2)\n",
    "    ax2.plot(history.history['val_loss'], label='Validation', linewidth=2)\n",
    "    ax2.set_title(f'{title} ‚Äî Loss')\n",
    "    ax2.set_xlabel('√âpoque')\n",
    "    ax2.set_ylabel('Loss')\n",
    "    ax2.legend()\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_training(history_scratch, \"CNN from scratch\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚ùì QUESTION\n",
    "\n",
    "Observez les courbes :\n",
    "- Quelle est l'accuracy sur les donn√©es de validation √† la derni√®re √©poque ?\n",
    "- La courbe de train et la courbe de validation divergent-elles ? Si oui, que signifie cette divergence ?\n",
    "- Ce mod√®le est-il satisfaisant pour distinguer un chat d'un chien ?\n",
    "\n",
    "*Rappel : si le train monte mais la validation stagne ou descend, c'est de l'**overfitting** ‚Äî le mod√®le m√©morise les images d'entra√Ænement au lieu d'apprendre √† g√©n√©raliser.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*(vos observations ici)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## √âtape 2 ‚Äî Transfer Learning avec MobileNetV2\n",
    "\n",
    "Le mod√®le from scratch n'est pas terrible. Normal : on a seulement ~2000 images d'entra√Ænement et un petit r√©seau.\n",
    "\n",
    "Maintenant, on va utiliser le **Transfer Learning** : r√©utiliser un mod√®le d√©j√† entra√Æn√© sur **1,4 million d'images** (ImageNet) et l'adapter √† notre probl√®me.\n",
    "\n",
    "Le mod√®le choisi est **MobileNetV2** :\n",
    "- L√©ger (~3,4 millions de param√®tres)\n",
    "- Rapide √† ex√©cuter (con√ßu pour les appareils mobiles)\n",
    "- Tr√®s performant malgr√© sa taille\n",
    "\n",
    "### 2.1 ‚Äî Charger le mod√®le pr√©-entra√Æn√©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger MobileNetV2 pr√©-entra√Æn√© sur ImageNet\n",
    "# include_top=False : on retire la derni√®re couche (qui classifie 1000 cat√©gories ImageNet)\n",
    "# On n'en veut pas : nous on a seulement 2 cat√©gories (chat / chien)\n",
    "\n",
    "base_model = keras.applications.MobileNetV2(\n",
    "    input_shape=(160, 160, 3),\n",
    "    include_top=False,          # on retire la t√™te de classification\n",
    "    weights='imagenet'          # on charge les poids pr√©-entra√Æn√©s\n",
    ")\n",
    "\n",
    "print(f\"Nombre de couches dans MobileNetV2 : {len(base_model.layers)}\")\n",
    "print(f\"Nombre de param√®tres : {base_model.count_params():,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ü§ñ GEMINI ‚Äî Comprendre MobileNetV2\n",
    "\n",
    "Demandez √† Gemini :\n",
    "\n",
    "> *\"Qu'est-ce que MobileNetV2 ? Sur quel dataset a-t-il √©t√© entra√Æn√© ? Combien de classes peut-il reconna√Ætre √† l'origine ? Pourquoi utilise-t-on `include_top=False` ?\"*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 ‚Äî Geler toutes les couches\n",
    "\n",
    "C'est l'√©tape cl√© du Transfer Learning. On **g√®le** toutes les couches du mod√®le pr√©-entra√Æn√© pour que leurs poids ne soient pas modifi√©s pendant notre entra√Ænement.\n",
    "\n",
    "Ces poids ont √©t√© appris sur 1,4 million d'images. Ils savent d√©j√† reconna√Ætre des bords, des textures, des formes, des objets. On ne veut pas perdre tout √ßa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GELER toutes les couches du mod√®le pr√©-entra√Æn√©\n",
    "base_model.trainable = False\n",
    "\n",
    "# V√©rification\n",
    "print(f\"Param√®tres totaux : {base_model.count_params():,}\")\n",
    "print(f\"Param√®tres entra√Ænables : {sum(tf.keras.backend.count_params(w) for w in base_model.trainable_weights):,}\")\n",
    "print(f\"Param√®tres gel√©s : {sum(tf.keras.backend.count_params(w) for w in base_model.non_trainable_weights):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚ùì QUESTION\n",
    "\n",
    "Combien de param√®tres sont entra√Ænables apr√®s le gel ? Pourquoi ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*(votre r√©ponse ici)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 ‚Äî Ajouter notre t√™te de classification\n",
    "\n",
    "On a retir√© la t√™te de MobileNetV2 (qui classifiait 1000 cat√©gories). On la remplace par la n√¥tre : une simple couche qui classifie **chat ou chien**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pr√©-traitement sp√©cifique √† MobileNetV2\n",
    "# Ce mod√®le attend des pixels entre -1 et 1 (pas entre 0 et 255)\n",
    "preprocess_input = keras.applications.mobilenet_v2.preprocess_input\n",
    "\n",
    "# Construire le mod√®le complet\n",
    "inputs = keras.Input(shape=(160, 160, 3))\n",
    "\n",
    "# 1. Pr√©-traitement\n",
    "x = preprocess_input(inputs)\n",
    "\n",
    "# 2. Le mod√®le pr√©-entra√Æn√© (gel√©) extrait les features\n",
    "x = base_model(x, training=False)\n",
    "\n",
    "# 3. Convertir les features en un vecteur\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "\n",
    "# 4. Un peu de dropout pour √©viter l'overfitting\n",
    "x = layers.Dropout(0.2)(x)\n",
    "\n",
    "# 5. La couche finale : 1 neurone = chat (0) ou chien (1)\n",
    "outputs = layers.Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "# Assembler le tout\n",
    "tl_model = keras.Model(inputs, outputs)\n",
    "\n",
    "tl_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ü§ñ GEMINI ‚Äî Comprendre l'architecture\n",
    "\n",
    "Demandez √† Gemini :\n",
    "\n",
    "> *\"Dans le code ci-dessus, explique-moi le r√¥le de `GlobalAveragePooling2D` et de `Dropout(0.2)`. Pourquoi les utilise-t-on ici ?\"*\n",
    "\n",
    "> *\"Combien de param√®tres sont entra√Ænables dans ce mod√®le ? Compare avec le mod√®le from scratch.\"*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 ‚Äî Compiler et entra√Æner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tl_model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "print(\"Entra√Ænement du mod√®le Transfer Learning...\")\n",
    "print(\"(cela prend environ 1-2 minutes)\")\n",
    "\n",
    "history_tl = tl_model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=val_dataset,\n",
    "    epochs=10\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 ‚Äî Visualiser les r√©sultats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_training(history_tl, \"Transfer Learning ‚Äî MobileNetV2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## √âtape 3 ‚Äî Comparer les deux approches\n",
    "\n",
    "C'est le moment cl√©. On met c√¥te √† c√¥te les r√©sultats du mod√®le from scratch et du Transfer Learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Accuracy\n",
    "axes[0].plot(history_scratch.history['val_accuracy'], label='From scratch', linewidth=2, linestyle='--')\n",
    "axes[0].plot(history_tl.history['val_accuracy'], label='Transfer Learning', linewidth=2)\n",
    "axes[0].set_title('Accuracy sur la validation')\n",
    "axes[0].set_xlabel('√âpoque')\n",
    "axes[0].set_ylabel('Accuracy')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "axes[0].set_ylim([0.4, 1.0])\n",
    "\n",
    "# Loss\n",
    "axes[1].plot(history_scratch.history['val_loss'], label='From scratch', linewidth=2, linestyle='--')\n",
    "axes[1].plot(history_tl.history['val_loss'], label='Transfer Learning', linewidth=2)\n",
    "axes[1].set_title('Loss sur la validation')\n",
    "axes[1].set_xlabel('√âpoque')\n",
    "axes[1].set_ylabel('Loss')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# R√©sum√© chiffr√©\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"R√âSUM√â\")\n",
    "print(\"=\"*50)\n",
    "print(f\"From scratch   ‚Äî Validation accuracy : {history_scratch.history['val_accuracy'][-1]:.1%}\")\n",
    "print(f\"Transfer Learning ‚Äî Validation accuracy : {history_tl.history['val_accuracy'][-1]:.1%}\")\n",
    "print(f\"\")\n",
    "print(f\"From scratch   ‚Äî Param√®tres entra√Æn√©s : {scratch_model.count_params():,}\")\n",
    "print(f\"Transfer Learning ‚Äî Param√®tres entra√Æn√©s : {tl_model.count_params() - base_model.count_params():,} (sur {tl_model.count_params():,} total)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚ùì QUESTIONS\n",
    "\n",
    "Observez attentivement les courbes et les chiffres :\n",
    "\n",
    "1. **Performance** : quelle est la diff√©rence d'accuracy entre les deux mod√®les ?\n",
    "2. **D√©marrage** : √† quelle accuracy le mod√®le Transfer Learning commence-t-il d√®s la premi√®re √©poque ? Pourquoi d√©marre-t-il si haut ?\n",
    "3. **Overfitting** : lequel des deux mod√®les montre le plus de signes d'overfitting ?\n",
    "4. **Param√®tres** : combien de param√®tres entra√Æne-t-on dans chaque cas ? Qu'est-ce que cela implique en termes de temps de calcul ?\n",
    "5. **Conclusion** : pourquoi le Transfer Learning fonctionne-t-il mieux avec si peu de donn√©es ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*(vos r√©ponses ici)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## √âtape 4 ‚Äî Exp√©rimenter\n",
    "\n",
    "Maintenant c'est √† vous de jouer. Choisissez **une ou plusieurs** exp√©rimentations parmi les suivantes.\n",
    "\n",
    "Pour chaque exp√©rimentation :\n",
    "1. Demandez √† Gemini de g√©n√©rer le code\n",
    "2. Lisez le code et demandez-lui de vous l'expliquer\n",
    "3. Ex√©cutez et observez les r√©sultats\n",
    "4. Notez vos conclusions\n",
    "\n",
    "---\n",
    "\n",
    "### Exp√©rimentation A ‚Äî Essayer un autre mod√®le pr√©-entra√Æn√©\n",
    "\n",
    "MobileNetV2 n'est pas le seul mod√®le disponible. Essayez avec **EfficientNetB0** ou **ResNet50**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ü§ñ GEMINI\n",
    "\n",
    "Demandez √† Gemini :\n",
    "\n",
    "> *\"R√©√©cris le code de l'√©tape 2 en rempla√ßant MobileNetV2 par EfficientNetB0 (ou ResNet50). Garde la m√™me structure : charger le mod√®le pr√©-entra√Æn√© sans la couche de sortie, geler les couches, ajouter GlobalAveragePooling2D, Dropout et une couche Dense sigmoid. Adapte la fonction de pr√©-traitement au mod√®le choisi.\"*\n",
    "\n",
    "Puis demandez :\n",
    "\n",
    "> *\"Quelle est la diff√©rence entre MobileNetV2 et EfficientNetB0 ? Lequel a le plus de param√®tres ?\"*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VOTRE CODE G√âN√âR√â PAR GEMINI ICI\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚ùì QUESTION\n",
    "\n",
    "Comparez les r√©sultats avec MobileNetV2 :\n",
    "- L'accuracy est-elle meilleure, moins bonne, ou similaire ?\n",
    "- L'entra√Ænement a-t-il √©t√© plus long ?\n",
    "- Le mod√®le est-il plus gros (plus de param√®tres) ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*(vos observations ici)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Exp√©rimentation B ‚Äî Ajouter du Data Augmentation\n",
    "\n",
    "Le Data Augmentation cr√©e des variantes des images d'entra√Ænement (rotation, retournement, zoom) pour \"augmenter\" artificiellement la taille du dataset et r√©duire l'overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ü§ñ GEMINI\n",
    "\n",
    "Demandez √† Gemini :\n",
    "\n",
    "> *\"Ajoute des couches de Data Augmentation au mod√®le de Transfer Learning MobileNetV2. Utilise RandomFlip horizontal, RandomRotation de 0.2, et RandomZoom de 0.2. Place ces couches avant le preprocess_input. Montre-moi aussi le code pour afficher 9 versions augment√©es d'une m√™me image.\"*\n",
    "\n",
    "Puis demandez :\n",
    "\n",
    "> *\"Pourquoi le Data Augmentation aide-t-il √† r√©duire l'overfitting ?\"*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VOTRE CODE G√âN√âR√â PAR GEMINI ICI\n",
    "# 1. Afficher les images augment√©es\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VOTRE CODE G√âN√âR√â PAR GEMINI ICI\n",
    "# 2. Mod√®le avec Data Augmentation + entra√Ænement\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚ùì QUESTION\n",
    "\n",
    "- L'√©cart entre train et validation a-t-il diminu√© par rapport au mod√®le sans augmentation ?\n",
    "- L'accuracy de validation a-t-elle chang√© ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*(vos observations ici)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Exp√©rimentation C ‚Äî Changer le nombre d'√©poques\n",
    "\n",
    "On a entra√Æn√© pendant 10 √©poques. Que se passe-t-il si on entra√Æne plus longtemps ? Ou moins longtemps ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ü§ñ GEMINI\n",
    "\n",
    "Demandez √† Gemini :\n",
    "\n",
    "> *\"Reprends le mod√®le Transfer Learning MobileNetV2 de l'√©tape 2 et entra√Æne-le pendant 3 √©poques, puis dans un second temps pendant 20 √©poques. Affiche les courbes de chaque entra√Ænement.\"*\n",
    "\n",
    "Puis demandez :\n",
    "\n",
    "> *\"√Ä quoi sert l'EarlyStopping dans Keras ? Comment l'utiliser pour arr√™ter l'entra√Ænement automatiquement quand le mod√®le n'apprend plus ?\"*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VOTRE CODE G√âN√âR√â PAR GEMINI ICI\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚ùì QUESTION\n",
    "\n",
    "- √Ä partir de quelle √©poque le mod√®le n'apprend plus (la validation accuracy stagne) ?\n",
    "- √Ä partir de quelle √©poque commence l'overfitting ?\n",
    "- Quel serait le nombre id√©al d'√©poques pour ce mod√®le ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*(vos observations ici)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## √âtape 5 ‚Äî Tester le mod√®le sur vos propres images\n",
    "\n",
    "C'est le moment de v√©rit√© ! On va utiliser notre mod√®le pour classifier des images de chats et de chiens que vous choisissez."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 ‚Äî Uploader une image\n",
    "\n",
    "Ex√©cutez la cellule ci-dessous, puis uploadez une image de chat ou de chien depuis votre ordinateur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "\n",
    "print(\"Uploadez une image de chat ou de chien :\")\n",
    "uploaded = files.upload()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 ‚Äî Pr√©diction\n",
    "\n",
    "Le mod√®le va analyser votre image et dire s'il pense que c'est un chat ou un chien."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in uploaded.keys():\n",
    "    # Charger et redimensionner l'image\n",
    "    img = keras.utils.load_img(filename, target_size=(160, 160))\n",
    "    img_array = keras.utils.img_to_array(img)\n",
    "    img_array = tf.expand_dims(img_array, 0)  # Ajouter la dimension batch\n",
    "\n",
    "    # Pr√©diction\n",
    "    prediction = tl_model.predict(img_array)\n",
    "    score = prediction[0][0]\n",
    "\n",
    "    # Afficher le r√©sultat\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.imshow(keras.utils.load_img(filename))\n",
    "    plt.axis('off')\n",
    "\n",
    "    if score > 0.5:\n",
    "        label = \"üêï CHIEN\"\n",
    "        confidence = score\n",
    "    else:\n",
    "        label = \"üêà CHAT\"\n",
    "        confidence = 1 - score\n",
    "\n",
    "    plt.title(f\"{label}\\nConfiance : {confidence:.1%}\", fontsize=16)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ü§ñ GEMINI ‚Äî Aller plus loin\n",
    "\n",
    "Demandez √† Gemini :\n",
    "\n",
    "> *\"Modifie le code de pr√©diction pour qu'il puisse tester plusieurs images d'un coup et afficher les r√©sultats dans une grille 2x2 avec les pr√©dictions et la confiance.\"*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VOTRE CODE G√âN√âR√â PAR GEMINI ICI\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚ùì QUESTIONS\n",
    "\n",
    "- Le mod√®le a-t-il correctement classifi√© vos images ?\n",
    "- Essayez avec une image ambigu√´ (un chat qui ressemble √† un chien, ou un animal vu de loin). Que se passe-t-il ?\n",
    "- Essayez avec une image qui n'est ni un chat ni un chien (un oiseau, une voiture, un paysage). Que pr√©dit le mod√®le ? Pourquoi ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*(vos observations ici)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## √âtape 6 ‚Äî Synth√®se\n",
    "\n",
    "Vous avez construit et compar√© deux approches pour classifier des images :\n",
    "\n",
    "| | From scratch | Transfer Learning |\n",
    "|---|---|---|\n",
    "| **Principe** | Tout entra√Æner √† partir de z√©ro | R√©utiliser un mod√®le pr√©-entra√Æn√© |\n",
    "| **Donn√©es n√©cessaires** | Beaucoup | Peu |\n",
    "| **Temps d'entra√Ænement** | Plus long | Plus court |\n",
    "| **Performance** | Limit√©e | √âlev√©e |\n",
    "| **Param√®tres entra√Æn√©s** | Tous | Seulement la t√™te |\n",
    "\n",
    "### ‚ùì QUESTIONS FINALES\n",
    "\n",
    "1. Dans votre domaine professionnel, imaginez un cas d'usage o√π le Transfer Learning serait utile. D√©crivez-le en 2-3 phrases.\n",
    "\n",
    "2. Un coll√®gue vous dit : *\"J'ai 500 images de pi√®ces industrielles d√©fectueuses et je veux entra√Æner un mod√®le de d√©tection from scratch.\"* Que lui conseillez-vous ?\n",
    "\n",
    "3. Qu'est-ce qui vous a le plus surpris dans cet atelier ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*(vos r√©ponses ici)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Pour aller plus loin (optionnel)\n",
    "\n",
    "Si vous avez du temps et de la curiosit√©, voici quelques pistes d'exploration. Utilisez Gemini pour vous guider.\n",
    "\n",
    "- **Autre dataset** : demandez √† Gemini de charger le dataset [Flowers](https://www.tensorflow.org/datasets/catalog/tf_flowers) (5 cat√©gories de fleurs) et adaptez le mod√®le Transfer Learning\n",
    "- **Visualiser les features** : demandez √† Gemini de vous montrer ce que \"voit\" chaque couche du mod√®le (feature maps)\n",
    "- **Matrice de confusion** : demandez √† Gemini de g√©n√©rer une matrice de confusion pour voir en d√©tail les erreurs du mod√®le\n",
    "- **Comparer 3 mod√®les** : MobileNetV2, EfficientNetB0, ResNet50 ‚Äî sur le m√™me dataset, m√™mes conditions, dans un tableau r√©capitulatif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VOTRE EXPLORATION ICI\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  },
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
