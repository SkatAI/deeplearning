{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Keras Callback\n",
        "\n",
        "Dans ce notebook nous allons ajouter un callback EarlyStopping qui arrete l'entraînement quand le gain de performance stagne.\n",
        "\n",
        "On va appliquer ce callback sur le loss pendant l'etape de fit()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Pd0jgdrXmHnM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c4_uVdIimD6-"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Le dataset CIFAR-10\n",
        "\n",
        "https://www.cs.toronto.edu/~kriz/cifar.html\n",
        "\n",
        "Une collection de 60k images en couleur de petite taille 32x32 classées en 10 catégories. chaque catégorie contient 6000 images.\n",
        "\n",
        "\n",
        "\n",
        "- airplane\n",
        "- automobile\n",
        "- bird\n",
        "- cat\n",
        "- deer\n",
        "- dog\n",
        "- frog\n",
        "- horse\n",
        "- ship\n",
        "- truck"
      ],
      "metadata": {
        "id": "H29b9T_PalcO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# charger le dataset à partir de Keras\n",
        "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.cifar10.load_data()"
      ],
      "metadata": {
        "id": "rKI8zYQamUCP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# verifier la présence des images\n",
        "! ls -al /root/.keras/datasets/"
      ],
      "metadata": {
        "id": "14TNuBn1bcQb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Afficher une image\n",
        "idx = 88\n",
        "\n",
        "print(f'LABEL: {train_labels[idx]} ')\n",
        "fig, ax = plt.subplots(1,1, figsize = (1,1))\n",
        "plt.imshow(train_images[idx])\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "9dQkbTQSmcX0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# le modele"
      ],
      "metadata": {
        "id": "2YOM-9XJk9ie"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## construire le modele et le compiler\n",
        "\n",
        "'''\n",
        "-- ecrire une fonction create_model qui prend n_nodes et lr en entree\n",
        "et qui crée et compile un model sequential avec les couches Flatten, Dense : activation relu, et Dense avec activation softmax\n",
        "la fonction retourne le modele compilé\n",
        "'''\n",
        "def create_model(n_nodes = 256, lr = 0.01):\n",
        "    model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Flatten(input_shape=(32, 32, 3)),\n",
        "    tf.keras.layers.Dense(n_nodes, activation=tf.nn.relu),\n",
        "    tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
        "    ])\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(optimizer=tf.optimizers.Adam(  learning_rate=lr),\n",
        "                loss='sparse_categorical_crossentropy',\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "9OObuWGgoPPx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "N'hesitez pas a changer les parametres\n",
        "- n_nodes = 128, 1024\n",
        "- lr = 0.2, 0.000001, etc ...\n",
        "etc"
      ],
      "metadata": {
        "id": "3YZhdxAMkmBv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = create_model(n_nodes = 256, lr = 0.01 )"
      ],
      "metadata": {
        "id": "uTGzAUxEzKa0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "P0qPwFbyqmv6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Rajoutons maintenant le callback early_stopping dans la phase d'entraînement\n",
        "\n",
        "https://keras.io/api/callbacks/early_stopping/"
      ],
      "metadata": {
        "id": "NalYo45zxkCY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3, verbose = 1, min_delta = 0.001)"
      ],
      "metadata": {
        "id": "KiY8Ldk1vso8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notez les functions du callback :\n",
        "\n",
        "- quand: on_epoch_end, on_epoch_begin\n",
        "- le meilleur modele : restore_best_weights\n",
        "- faire un minimum d'iterations : start_from_epoch"
      ],
      "metadata": {
        "id": "rpwaiBJfiawn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "early_stopping\n"
      ],
      "metadata": {
        "id": "1LAZ9FlVheQY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# entrainer le modele avec beaucoup d'epochs\n",
        "\n",
        "history = model.fit(train_images, train_labels, epochs=25, callbacks=[early_stopping])"
      ],
      "metadata": {
        "id": "JO_Uko70qsiY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# acceder aux courbes accuracy et loss\n",
        "history.history['accuracy']"
      ],
      "metadata": {
        "id": "R2E33QbHuaug"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## reduire le learning rate\n",
        "\n",
        "Ajoutons un autre callback qui réduit le learning rate quand la valeur loss stagne\n",
        "\n",
        "https://keras.io/api/callbacks/reduce_lr_on_plateau/\n",
        "\n",
        "\n",
        "### questions\n",
        "\n",
        "- Pourquoi réduire le learnign rate ?\n",
        "- Pourquoi ne pas simplement fixer un learning rate bas des le depart ?\n",
        "- Comment gérer les 2 patiences entre les 2 callbacks ? L'une doit elle etre necessairement inferieure a l'autre ?"
      ],
      "metadata": {
        "id": "uowvShuixgaI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# reset le modele\n",
        "model = create_model(n_nodes = 128, lr = 0.02 )\n",
        "\n",
        "# callbacks\n",
        "# early stopping\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=4, verbose = 1)\n",
        "# rajouter le call back ReduceLROnPlateau\n",
        "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='loss', factor=0.2, patience=2, min_lr=0.001, verbose = 1)\n",
        "\n",
        "\n",
        "history = model.fit(train_images, train_labels, epochs=25, callbacks=[early_stopping, reduce_lr])"
      ],
      "metadata": {
        "id": "LVfH5n8ewXOb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Qu'observez vous ?\n",
        "\n",
        "- learning rate\n",
        "- loss\n",
        "- nombre d'epochs\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "### Visualisez\n",
        "\n",
        "Afficher dans une figure l'evolution du loss, du learning et de l'accuracy"
      ],
      "metadata": {
        "id": "NYV4zIUjgk6y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(3,1, figsize = (8,8))\n",
        "plt.subplot(3,1,1)\n",
        "plt.plot(history.history['accuracy'][1:], label = 'accuracy')\n",
        "plt.subplot(3,1,2)\n",
        "plt.xlabel('accuracy')\n",
        "plt.grid(visible = True)\n",
        "plt.plot(history.history['loss'][1:], label = 'loss')\n",
        "plt.xlabel('loss')\n",
        "plt.grid(visible = True)\n",
        "plt.subplot(3,1,3)\n",
        "plt.plot(history.history['lr'][1:], label = 'learning_rate')\n",
        "plt.xlabel('lr')\n",
        "plt.grid(visible = True)\n",
        "plt.tight_layout()"
      ],
      "metadata": {
        "collapsed": true,
        "id": "2T5BcVOtxSbl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pa7TiSpSnYmD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}