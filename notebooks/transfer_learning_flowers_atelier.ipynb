{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning ‚Äî Atelier pratique\n",
    "\n",
    "**Deep Learning par la pratique ‚Äî Alexis Perrier**\n",
    "\n",
    "---\n",
    "\n",
    "## Objectifs de cet atelier\n",
    "\n",
    "1. **Comprendre le Transfer Learning** : pourquoi on ne part jamais de z√©ro en deep learning\n",
    "2. **Travailler avec l'IA** : utiliser Gemini pour g√©n√©rer, lire et comprendre du code\n",
    "\n",
    "## Comment utiliser ce notebook\n",
    "\n",
    "- Les cellules avec du code pr√©-√©crit : **lisez, ex√©cutez, observez**\n",
    "- Les cellules marqu√©es ü§ñ **GEMINI** : demandez √† Gemini de g√©n√©rer le code, puis lisez-le et demandez-lui de vous l'expliquer\n",
    "- Les cellules marqu√©es ‚ùì **QUESTION** : r√©pondez en observant les r√©sultats\n",
    "\n",
    "**Utiliser l'IA pour coder n'est pas tricher ‚Äî c'est la m√©thode de travail.**\n",
    "Votre valeur n'est pas de taper du code, c'est de savoir quoi demander, comprendre ce qu'on vous donne, et juger si le r√©sultat est bon.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## √âtape 0 ‚Äî Setup et exploration des donn√©es\n",
    "\n",
    "On travaille avec le dataset **tf_flowers** : des photos de 5 types de fleurs.\n",
    "Notre objectif : construire un mod√®le qui les distingue.\n",
    "\n",
    "Les 5 classes :\n",
    "- üåº Daisy (p√¢querette)\n",
    "- üå∑ Tulip (tulipe)\n",
    "- üåπ Rose\n",
    "- üåª Sunflower (tournesol)\n",
    "- üå∏ Dandelion (pissenlit)\n",
    "\n",
    "### 0.1 ‚Äî Installer et importer les librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow_datasets as tfds\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"GPU disponible: {tf.config.list_physical_devices('GPU')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.2 ‚Äî T√©l√©charger le dataset\n",
    "\n",
    "Le dataset tf_flowers contient 3 670 images de fleurs r√©parties en 5 cat√©gories.\n",
    "On le charge directement depuis TensorFlow Datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger le dataset avec les informations\n",
    "(train_ds, val_ds), info = tfds.load(\n",
    "    'tf_flowers',\n",
    "    split=['train[:80%]', 'train[80%:]'],  # 80% train, 20% validation\n",
    "    as_supervised=True,                     # retourne (image, label)\n",
    "    with_info=True\n",
    ")\n",
    "\n",
    "# Les noms des classes\n",
    "class_names = info.features['label'].names\n",
    "num_classes = len(class_names)\n",
    "\n",
    "print(f\"Classes : {class_names}\")\n",
    "print(f\"Nombre de classes : {num_classes}\")\n",
    "print(f\"Nombre total d'images : {info.splits['train'].num_examples}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.3 ‚Äî Pr√©parer les images\n",
    "\n",
    "Les images du dataset ont des tailles diff√©rentes. On les redimensionne toutes √† 160x160 pixels et on les regroupe en lots (batches) de 32."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = (160, 160)\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "def preprocess(image, label):\n",
    "    \"\"\"Redimensionne l'image √† 160x160.\"\"\"\n",
    "    image = tf.image.resize(image, IMG_SIZE)\n",
    "    return image, label\n",
    "\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "train_dataset = (\n",
    "    train_ds\n",
    "    .map(preprocess, num_parallel_calls=AUTOTUNE)\n",
    "    .shuffle(1000)\n",
    "    .batch(BATCH_SIZE)\n",
    "    .prefetch(AUTOTUNE)\n",
    ")\n",
    "\n",
    "val_dataset = (\n",
    "    val_ds\n",
    "    .map(preprocess, num_parallel_calls=AUTOTUNE)\n",
    "    .batch(BATCH_SIZE)\n",
    "    .prefetch(AUTOTUNE)\n",
    ")\n",
    "\n",
    "print(\"Datasets pr√™ts !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ü§ñ GEMINI ‚Äî Visualiser les donn√©es\n",
    "\n",
    "Demandez √† Gemini :\n",
    "\n",
    "> *\"G√©n√®re du code pour afficher une grille de 12 images du dataset `train_dataset` avec le nom de la fleur en titre. Les noms des classes sont dans la liste `class_names`. Utilise matplotlib avec une grille 3x4.\"*\n",
    "\n",
    "Ensuite, demandez-lui :\n",
    "\n",
    "> *\"Explique-moi ce que fait chaque ligne de ce code.\"*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VOTRE CODE G√âN√âR√â PAR GEMINI ICI\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚ùì QUESTION\n",
    "\n",
    "En observant les images :\n",
    "- Certaines classes se ressemblent-elles ? Lesquelles pourrait-on confondre ?\n",
    "- Y a-t-il des images \"difficiles\" (fleur mal cadr√©e, plusieurs fleurs, arri√®re-plan charg√©) ?\n",
    "- Pensez-vous qu'un humain ferait 100% de bonnes r√©ponses sur ce dataset ?\n",
    "\n",
    "*√âcrivez vos observations ci-dessous :*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*(vos observations ici)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## √âtape 1 ‚Äî Baseline : un petit CNN entra√Æn√© from scratch\n",
    "\n",
    "Avant d'utiliser le Transfer Learning, on va d'abord essayer de construire un mod√®le **√† partir de z√©ro** (from scratch). C'est notre **baseline** ‚Äî le point de r√©f√©rence.\n",
    "\n",
    "On construit un petit CNN (Convolutional Neural Network) avec 3 couches de convolution.\n",
    "\n",
    "### 1.1 ‚Äî Construire le mod√®le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scratch_model = keras.Sequential([\n",
    "    # Normalisation des pixels (0-255 ‚Üí 0-1)\n",
    "    layers.Rescaling(1./255, input_shape=(160, 160, 3)),\n",
    "\n",
    "    # Bloc 1 : d√©tecter des features simples (bords, textures)\n",
    "    layers.Conv2D(16, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D(2, 2),\n",
    "\n",
    "    # Bloc 2 : d√©tecter des features plus complexes (formes)\n",
    "    layers.Conv2D(32, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D(2, 2),\n",
    "\n",
    "    # Bloc 3 : features encore plus abstraites\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D(2, 2),\n",
    "\n",
    "    # Classification\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(num_classes)  # 5 sorties = 5 types de fleurs\n",
    "])\n",
    "\n",
    "scratch_model.compile(\n",
    "    optimizer='adam',\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "scratch_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ü§ñ GEMINI ‚Äî Comprendre l'architecture\n",
    "\n",
    "Demandez √† Gemini :\n",
    "\n",
    "> *\"Explique-moi le `model.summary()` ci-dessus. Que signifient les colonnes Output Shape et Param # ? Combien de param√®tres ce mod√®le a-t-il au total ? Pourquoi la derni√®re couche Dense a-t-elle 5 neurones et pas 1 ?\"*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 ‚Äî Entra√Æner le mod√®le from scratch\n",
    "\n",
    "On entra√Æne pendant 10 √©poques. Une √©poque = le mod√®le a vu toutes les images une fois."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Entra√Ænement du mod√®le from scratch...\")\n",
    "print(\"(cela prend environ 2-3 minutes)\")\n",
    "\n",
    "history_scratch = scratch_model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=val_dataset,\n",
    "    epochs=10\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 ‚Äî Visualiser les r√©sultats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training(history, title):\n",
    "    \"\"\"Affiche les courbes d'accuracy et de loss pour train et validation.\"\"\"\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "    # Accuracy\n",
    "    ax1.plot(history.history['accuracy'], label='Train', linewidth=2)\n",
    "    ax1.plot(history.history['val_accuracy'], label='Validation', linewidth=2)\n",
    "    ax1.set_title(f'{title} ‚Äî Accuracy')\n",
    "    ax1.set_xlabel('√âpoque')\n",
    "    ax1.set_ylabel('Accuracy')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    ax1.set_ylim([0.0, 1.0])\n",
    "\n",
    "    # Loss\n",
    "    ax2.plot(history.history['loss'], label='Train', linewidth=2)\n",
    "    ax2.plot(history.history['val_loss'], label='Validation', linewidth=2)\n",
    "    ax2.set_title(f'{title} ‚Äî Loss')\n",
    "    ax2.set_xlabel('√âpoque')\n",
    "    ax2.set_ylabel('Loss')\n",
    "    ax2.legend()\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_training(history_scratch, \"CNN from scratch\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚ùì QUESTION\n",
    "\n",
    "Observez les courbes :\n",
    "- Quelle est l'accuracy sur les donn√©es de validation √† la derni√®re √©poque ?\n",
    "- Rappel : avec 5 classes, un mod√®le qui r√©pond au hasard aurait **20% d'accuracy**. Le mod√®le fait-il beaucoup mieux ?\n",
    "- La courbe de train et la courbe de validation divergent-elles ? Si oui, que signifie cette divergence ?\n",
    "\n",
    "*Rappel : si le train monte mais la validation stagne ou descend, c'est de l'**overfitting** ‚Äî le mod√®le m√©morise les images d'entra√Ænement au lieu d'apprendre √† g√©n√©raliser.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*(vos observations ici)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## √âtape 2 ‚Äî Transfer Learning avec MobileNetV2\n",
    "\n",
    "Le mod√®le from scratch n'est pas terrible. Normal : on a seulement ~2 900 images d'entra√Ænement, 5 classes √† distinguer, et un petit r√©seau.\n",
    "\n",
    "Maintenant, on va utiliser le **Transfer Learning** : r√©utiliser un mod√®le d√©j√† entra√Æn√© sur **1,4 million d'images** (ImageNet) et l'adapter √† notre probl√®me.\n",
    "\n",
    "Le mod√®le choisi est **MobileNetV2** :\n",
    "- L√©ger (~3,4 millions de param√®tres)\n",
    "- Rapide √† ex√©cuter (con√ßu pour les appareils mobiles)\n",
    "- Tr√®s performant malgr√© sa taille\n",
    "\n",
    "### 2.1 ‚Äî Charger le mod√®le pr√©-entra√Æn√©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger MobileNetV2 pr√©-entra√Æn√© sur ImageNet\n",
    "# include_top=False : on retire la derni√®re couche (qui classifie 1000 cat√©gories ImageNet)\n",
    "# On n'en veut pas : nous on a seulement 5 cat√©gories (types de fleurs)\n",
    "\n",
    "base_model = keras.applications.MobileNetV2(\n",
    "    input_shape=(160, 160, 3),\n",
    "    include_top=False,          # on retire la t√™te de classification\n",
    "    weights='imagenet'          # on charge les poids pr√©-entra√Æn√©s\n",
    ")\n",
    "\n",
    "print(f\"Nombre de couches dans MobileNetV2 : {len(base_model.layers)}\")\n",
    "print(f\"Nombre de param√®tres : {base_model.count_params():,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ü§ñ GEMINI ‚Äî Comprendre MobileNetV2\n",
    "\n",
    "Demandez √† Gemini :\n",
    "\n",
    "> *\"Qu'est-ce que MobileNetV2 ? Sur quel dataset a-t-il √©t√© entra√Æn√© ? Combien de classes peut-il reconna√Ætre √† l'origine ? Pourquoi utilise-t-on `include_top=False` ?\"*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 ‚Äî Geler toutes les couches\n",
    "\n",
    "C'est l'√©tape cl√© du Transfer Learning. On **g√®le** toutes les couches du mod√®le pr√©-entra√Æn√© pour que leurs poids ne soient pas modifi√©s pendant notre entra√Ænement.\n",
    "\n",
    "Ces poids ont √©t√© appris sur 1,4 million d'images. Ils savent d√©j√† reconna√Ætre des bords, des textures, des formes, des objets. On ne veut pas perdre tout √ßa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GELER toutes les couches du mod√®le pr√©-entra√Æn√©\n",
    "base_model.trainable = False\n",
    "\n",
    "# V√©rification\n",
    "trainable_params = sum(tf.keras.backend.count_params(w) for w in base_model.trainable_weights)\n",
    "frozen_params = sum(tf.keras.backend.count_params(w) for w in base_model.non_trainable_weights)\n",
    "\n",
    "print(f\"Param√®tres totaux : {base_model.count_params():,}\")\n",
    "print(f\"Param√®tres entra√Ænables : {trainable_params:,}\")\n",
    "print(f\"Param√®tres gel√©s : {frozen_params:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚ùì QUESTION\n",
    "\n",
    "Combien de param√®tres sont entra√Ænables apr√®s le gel ? Pourquoi ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*(votre r√©ponse ici)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 ‚Äî Ajouter notre t√™te de classification\n",
    "\n",
    "On a retir√© la t√™te de MobileNetV2 (qui classifiait 1000 cat√©gories). On la remplace par la n√¥tre : une couche qui classifie **5 types de fleurs**.\n",
    "\n",
    "Notez la diff√©rence avec un probl√®me binaire (chat/chien) : ici on utilise **softmax** au lieu de sigmoid, et **5 neurones** au lieu de 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pr√©-traitement sp√©cifique √† MobileNetV2\n",
    "# Ce mod√®le attend des pixels entre -1 et 1 (pas entre 0 et 255)\n",
    "preprocess_input = keras.applications.mobilenet_v2.preprocess_input\n",
    "\n",
    "# Construire le mod√®le complet\n",
    "inputs = keras.Input(shape=(160, 160, 3))\n",
    "\n",
    "# 1. Pr√©-traitement des pixels pour MobileNetV2\n",
    "x = preprocess_input(inputs)\n",
    "\n",
    "# 2. Le mod√®le pr√©-entra√Æn√© (gel√©) extrait les features\n",
    "x = base_model(x, training=False)\n",
    "\n",
    "# 3. Convertir les features en un vecteur\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "\n",
    "# 4. Un peu de dropout pour √©viter l'overfitting\n",
    "x = layers.Dropout(0.2)(x)\n",
    "\n",
    "# 5. La couche finale : 5 neurones = 5 types de fleurs\n",
    "outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "# Assembler le tout\n",
    "tl_model = keras.Model(inputs, outputs)\n",
    "\n",
    "tl_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ü§ñ GEMINI ‚Äî Comprendre l'architecture\n",
    "\n",
    "Demandez √† Gemini :\n",
    "\n",
    "> *\"Dans le code ci-dessus, explique-moi la diff√©rence entre sigmoid et softmax. Pourquoi utilise-t-on softmax ici et pas sigmoid comme dans l'exemple cats vs dogs ?\"*\n",
    "\n",
    "> *\"Que fait `GlobalAveragePooling2D` et pourquoi l'utilise-t-on ici ?\"*\n",
    "\n",
    "> *\"Combien de param√®tres sont entra√Ænables dans ce mod√®le ? Compare avec le mod√®le from scratch.\"*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 ‚Äî Compiler et entra√Æner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tl_model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "print(\"Entra√Ænement du mod√®le Transfer Learning...\")\n",
    "print(\"(cela prend environ 1-2 minutes)\")\n",
    "\n",
    "history_tl = tl_model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=val_dataset,\n",
    "    epochs=10\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 ‚Äî Visualiser les r√©sultats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_training(history_tl, \"Transfer Learning ‚Äî MobileNetV2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## √âtape 3 ‚Äî Comparer les deux approches\n",
    "\n",
    "C'est le moment cl√©. On met c√¥te √† c√¥te les r√©sultats du mod√®le from scratch et du Transfer Learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Accuracy\n",
    "axes[0].plot(history_scratch.history['val_accuracy'], label='From scratch', linewidth=2, linestyle='--')\n",
    "axes[0].plot(history_tl.history['val_accuracy'], label='Transfer Learning', linewidth=2)\n",
    "axes[0].set_title('Accuracy sur la validation')\n",
    "axes[0].set_xlabel('√âpoque')\n",
    "axes[0].set_ylabel('Accuracy')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "axes[0].set_ylim([0.0, 1.0])\n",
    "axes[0].axhline(y=0.2, color='red', linestyle=':', alpha=0.5, label='Hasard (20%)')\n",
    "axes[0].legend()\n",
    "\n",
    "# Loss\n",
    "axes[1].plot(history_scratch.history['val_loss'], label='From scratch', linewidth=2, linestyle='--')\n",
    "axes[1].plot(history_tl.history['val_loss'], label='Transfer Learning', linewidth=2)\n",
    "axes[1].set_title('Loss sur la validation')\n",
    "axes[1].set_xlabel('√âpoque')\n",
    "axes[1].set_ylabel('Loss')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# R√©sum√© chiffr√©\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"R√âSUM√â\")\n",
    "print(\"=\"*50)\n",
    "scratch_acc = history_scratch.history['val_accuracy'][-1]\n",
    "tl_acc = history_tl.history['val_accuracy'][-1]\n",
    "print(f\"From scratch      ‚Äî Validation accuracy : {scratch_acc:.1%}\")\n",
    "print(f\"Transfer Learning ‚Äî Validation accuracy : {tl_acc:.1%}\")\n",
    "print(f\"Gain : +{(tl_acc - scratch_acc):.1%}\")\n",
    "print(f\"\")\n",
    "print(f\"From scratch      ‚Äî Param√®tres entra√Æn√©s : {scratch_model.count_params():,}\")\n",
    "tl_trainable = sum(tf.keras.backend.count_params(w) for w in tl_model.trainable_weights)\n",
    "print(f\"Transfer Learning ‚Äî Param√®tres entra√Æn√©s : {tl_trainable:,} (sur {tl_model.count_params():,} total)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚ùì QUESTIONS\n",
    "\n",
    "Observez attentivement les courbes et les chiffres :\n",
    "\n",
    "1. **Performance** : quelle est la diff√©rence d'accuracy entre les deux mod√®les ?\n",
    "2. **D√©marrage** : √† quelle accuracy le mod√®le Transfer Learning commence-t-il d√®s la premi√®re √©poque ? Pourquoi d√©marre-t-il si haut ?\n",
    "3. **Overfitting** : lequel des deux mod√®les montre le plus de signes d'overfitting ?\n",
    "4. **Hasard** : la ligne rouge pointill√©e indique 20% (le hasard pour 5 classes). Les deux mod√®les font-ils significativement mieux ?\n",
    "5. **Conclusion** : pourquoi le Transfer Learning fonctionne-t-il mieux avec si peu de donn√©es ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*(vos r√©ponses ici)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## √âtape 4 ‚Äî Exp√©rimenter\n",
    "\n",
    "Maintenant c'est √† vous de jouer. Choisissez **une ou plusieurs** exp√©rimentations parmi les suivantes.\n",
    "\n",
    "Pour chaque exp√©rimentation :\n",
    "1. Demandez √† Gemini de g√©n√©rer le code\n",
    "2. Lisez le code et demandez √† Gemini de vous l'expliquer\n",
    "3. Ex√©cutez et observez les r√©sultats\n",
    "4. Notez vos conclusions\n",
    "\n",
    "---\n",
    "\n",
    "### Exp√©rimentation A ‚Äî Essayer un autre mod√®le pr√©-entra√Æn√©\n",
    "\n",
    "MobileNetV2 n'est pas le seul mod√®le disponible. Essayez avec un autre."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ü§ñ GEMINI\n",
    "\n",
    "Demandez √† Gemini :\n",
    "\n",
    "> *\"R√©√©cris le code de l'√©tape 2 en rempla√ßant MobileNetV2 par EfficientNetB0 (ou ResNet50). Garde la m√™me structure : charger le mod√®le pr√©-entra√Æn√© sans la couche de sortie, geler les couches, ajouter GlobalAveragePooling2D, Dropout et une couche Dense softmax avec 5 classes. Adapte la fonction de pr√©-traitement au mod√®le choisi. Entra√Æne pendant 10 √©poques et affiche les courbes.\"*\n",
    "\n",
    "Puis demandez :\n",
    "\n",
    "> *\"Quelle est la diff√©rence entre MobileNetV2 et EfficientNetB0 ? Lequel a le plus de param√®tres ? Lequel est le plus rapide ?\"*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VOTRE CODE G√âN√âR√â PAR GEMINI ICI\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚ùì QUESTION\n",
    "\n",
    "Comparez les r√©sultats avec MobileNetV2 :\n",
    "- L'accuracy est-elle meilleure, moins bonne, ou similaire ?\n",
    "- L'entra√Ænement a-t-il √©t√© plus long ?\n",
    "- Le mod√®le est-il plus gros (plus de param√®tres) ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*(vos observations ici)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Exp√©rimentation B ‚Äî Ajouter du Data Augmentation\n",
    "\n",
    "Le Data Augmentation cr√©e des variantes des images d'entra√Ænement (rotation, retournement, zoom) pour \"augmenter\" artificiellement la taille du dataset et r√©duire l'overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ü§ñ GEMINI\n",
    "\n",
    "Demandez √† Gemini :\n",
    "\n",
    "> *\"Ajoute des couches de Data Augmentation au mod√®le de Transfer Learning MobileNetV2 de l'√©tape 2. Utilise RandomFlip horizontal, RandomRotation de 0.2, et RandomZoom de 0.2. Place ces couches avant le preprocess_input dans le mod√®le. Montre-moi aussi le code pour afficher 9 versions augment√©es d'une m√™me image du dataset.\"*\n",
    "\n",
    "Puis demandez :\n",
    "\n",
    "> *\"Pourquoi le Data Augmentation aide-t-il √† r√©duire l'overfitting ? Pourquoi on ne l'applique qu'aux donn√©es d'entra√Ænement et pas √† la validation ?\"*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VOTRE CODE G√âN√âR√â PAR GEMINI ICI\n",
    "# 1. Afficher les images augment√©es\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VOTRE CODE G√âN√âR√â PAR GEMINI ICI\n",
    "# 2. Mod√®le avec Data Augmentation + entra√Ænement\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚ùì QUESTION\n",
    "\n",
    "- L'√©cart entre train accuracy et validation accuracy a-t-il diminu√© par rapport au mod√®le sans augmentation ?\n",
    "- L'accuracy de validation a-t-elle chang√© ?\n",
    "- Regardez les images augment√©es : les transformations vous semblent-elles r√©alistes ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*(vos observations ici)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Exp√©rimentation C ‚Äî Changer le nombre d'√©poques\n",
    "\n",
    "On a entra√Æn√© pendant 10 √©poques. Que se passe-t-il si on entra√Æne plus longtemps ? Ou moins longtemps ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ü§ñ GEMINI\n",
    "\n",
    "Demandez √† Gemini :\n",
    "\n",
    "> *\"Reprends le mod√®le Transfer Learning MobileNetV2 de l'√©tape 2 et entra√Æne-le pendant 20 √©poques. Ajoute un EarlyStopping qui surveille la val_loss avec une patience de 3. Affiche les courbes d'entra√Ænement et indique √† quelle √©poque l'entra√Ænement s'est arr√™t√©.\"*\n",
    "\n",
    "Puis demandez :\n",
    "\n",
    "> *\"Explique-moi ce que fait EarlyStopping. Que signifie le param√®tre patience ? Pourquoi surveille-t-on la val_loss plut√¥t que la val_accuracy ?\"*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VOTRE CODE G√âN√âR√â PAR GEMINI ICI\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚ùì QUESTION\n",
    "\n",
    "- √Ä quelle √©poque l'EarlyStopping a-t-il arr√™t√© l'entra√Ænement ?\n",
    "- √Ä partir de quelle √©poque la validation accuracy stagnait-elle ?\n",
    "- Quel est l'int√©r√™t d'utiliser EarlyStopping plut√¥t que de choisir manuellement le nombre d'√©poques ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*(vos observations ici)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Exp√©rimentation D ‚Äî Quelles fleurs le mod√®le confond-il ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ü§ñ GEMINI\n",
    "\n",
    "Demandez √† Gemini :\n",
    "\n",
    "> *\"G√©n√®re le code pour afficher une matrice de confusion du mod√®le `tl_model` sur le `val_dataset`. Les noms des classes sont dans `class_names`. Utilise sklearn.metrics et matplotlib. Affiche la matrice avec des couleurs et les noms des fleurs sur les axes.\"*\n",
    "\n",
    "Puis demandez :\n",
    "\n",
    "> *\"Explique-moi comment lire une matrice de confusion. Que signifient les valeurs sur la diagonale ? Et celles hors diagonale ?\"*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VOTRE CODE G√âN√âR√â PAR GEMINI ICI\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚ùì QUESTION\n",
    "\n",
    "- Quelles fleurs le mod√®le confond-il le plus souvent ?\n",
    "- Cette confusion vous semble-t-elle logique visuellement ? (ces fleurs se ressemblent-elles ?)\n",
    "- Quelle classe est la mieux reconnue ? La moins bien reconnue ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*(vos observations ici)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## √âtape 5 ‚Äî Tester le mod√®le sur vos propres images\n",
    "\n",
    "C'est le moment de v√©rit√© ! On va utiliser notre mod√®le pour classifier des photos de fleurs que vous choisissez."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 ‚Äî Uploader une image\n",
    "\n",
    "Ex√©cutez la cellule ci-dessous, puis uploadez une photo de fleur depuis votre ordinateur (ou une image trouv√©e sur internet).\n",
    "\n",
    "Essayez avec :\n",
    "- une photo classique d'une des 5 fleurs\n",
    "- une photo ambigu√´ ou de mauvaise qualit√©\n",
    "- une fleur qui n'est **pas** dans les 5 cat√©gories (orchid√©e, iris, coquelicot...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "\n",
    "print(\"Uploadez une ou plusieurs images de fleurs :\")\n",
    "uploaded = files.upload()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 ‚Äî Pr√©diction\n",
    "\n",
    "Le mod√®le va analyser votre image et donner sa pr√©diction parmi les 5 types de fleurs, avec un niveau de confiance pour chaque classe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in uploaded.keys():\n",
    "    # Charger et redimensionner l'image\n",
    "    img = keras.utils.load_img(filename, target_size=(160, 160))\n",
    "    img_array = keras.utils.img_to_array(img)\n",
    "    img_array = tf.expand_dims(img_array, 0)  # Ajouter la dimension batch\n",
    "\n",
    "    # Pr√©diction\n",
    "    predictions = tl_model.predict(img_array, verbose=0)\n",
    "    scores = predictions[0]\n",
    "\n",
    "    # Afficher le r√©sultat\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "    # Image\n",
    "    ax1.imshow(keras.utils.load_img(filename))\n",
    "    ax1.axis('off')\n",
    "    predicted_class = class_names[np.argmax(scores)]\n",
    "    confidence = np.max(scores)\n",
    "    ax1.set_title(f\"Pr√©diction : {predicted_class}\\nConfiance : {confidence:.1%}\", fontsize=14)\n",
    "\n",
    "    # Barres de confiance pour chaque classe\n",
    "    colors = ['#ff6b6b' if i != np.argmax(scores) else '#51cf66' for i in range(num_classes)]\n",
    "    ax2.barh(class_names, scores, color=colors)\n",
    "    ax2.set_xlim([0, 1])\n",
    "    ax2.set_xlabel('Confiance')\n",
    "    ax2.set_title('Score par classe')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚ùì QUESTIONS\n",
    "\n",
    "- Le mod√®le a-t-il correctement classifi√© vos images ?\n",
    "- Quand le mod√®le se trompe, regardez le diagramme en barres : la bonne r√©ponse est-elle quand m√™me en deuxi√®me position ?\n",
    "- Que se passe-t-il quand vous uploadez une fleur qui n'est **pas** dans les 5 cat√©gories ? Le mod√®le le sait-il ? Pourquoi ?\n",
    "- Que se passe-t-il avec une image qui n'est pas du tout une fleur (un chat, une voiture) ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*(vos observations ici)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## √âtape 6 ‚Äî Synth√®se\n",
    "\n",
    "Vous avez construit et compar√© deux approches pour classifier des images de fleurs :\n",
    "\n",
    "| | From scratch | Transfer Learning |\n",
    "|---|---|---|\n",
    "| **Principe** | Tout entra√Æner √† partir de z√©ro | R√©utiliser un mod√®le pr√©-entra√Æn√© |\n",
    "| **Donn√©es n√©cessaires** | Beaucoup | Peu |\n",
    "| **Temps d'entra√Ænement** | Plus long | Plus court |\n",
    "| **Performance** | Limit√©e | √âlev√©e |\n",
    "| **Param√®tres entra√Æn√©s** | Tous | Seulement la t√™te de classification |\n",
    "\n",
    "### ‚ùì QUESTIONS FINALES\n",
    "\n",
    "1. Dans votre domaine professionnel, imaginez un cas d'usage o√π le Transfer Learning serait utile. D√©crivez-le en 2-3 phrases.\n",
    "\n",
    "2. Un coll√®gue vous dit : *\"J'ai 500 photos de pi√®ces industrielles d√©fectueuses et je veux entra√Æner un mod√®le de d√©tection from scratch.\"* Que lui conseillez-vous ?\n",
    "\n",
    "3. On a vu que le mod√®le pr√©dit toujours une des 5 fleurs, m√™me pour une photo de chat. Est-ce un probl√®me ? Comment pourrait-on le r√©soudre ?\n",
    "\n",
    "4. Qu'est-ce qui vous a le plus surpris dans cet atelier ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*(vos r√©ponses ici)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Pour aller plus loin (optionnel)\n",
    "\n",
    "Si vous avez du temps et de la curiosit√©, voici quelques pistes d'exploration. Utilisez Gemini pour vous guider.\n",
    "\n",
    "- **Visualiser les features** : demandez √† Gemini *\"Montre-moi ce que voit la premi√®re couche de convolution de MobileNetV2 quand on lui donne une image de tournesol\"*\n",
    "- **Comparer 3 mod√®les** : MobileNetV2, EfficientNetB0, ResNet50 ‚Äî m√™me dataset, m√™mes conditions, dans un tableau r√©capitulatif\n",
    "- **Autre dataset** : demandez √† Gemini de charger le dataset `rock_paper_scissors` depuis tensorflow_datasets et adaptez le mod√®le\n",
    "- **Afficher les erreurs** : demandez √† Gemini de montrer les images que le mod√®le a mal classifi√©es ‚Äî que remarquez-vous ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VOTRE EXPLORATION ICI\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  },
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
