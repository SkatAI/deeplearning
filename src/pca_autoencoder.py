# -*- coding: utf-8 -*-
"""PCA - autoencoder

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ovUTob-USLyIK2FigpNJlq325do2rBpw
"""

import numpy as np
import tensorflow as tf
from tensorflow.keras.layers import Input, Dense
from tensorflow.keras.models import Model
from sklearn.datasets import load_iris
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt

# Load and prepare the Iris dataset
iris = load_iris()
data = iris.data
labels = iris.target

# Standardize the data
scaler = StandardScaler()
data = scaler.fit_transform(data)

# Split into train and test sets
X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.3, random_state=42)

# Define the autoencoder model
input_dim = X_train.shape[1]
encoding_dim = 2  # Reduce to 2 dimensions for visualization

# Input layer
input_layer = Input(shape=(input_dim,))

# Encoding layer
encoded = Dense(encoding_dim, activation='relu')(input_layer)

# Decoding layer
decoded = Dense(input_dim, activation='sigmoid')(encoded)

# Autoencoder model
autoencoder = Model(input_layer, decoded)

# Encoder model to extract the reduced representation
encoder = Model(input_layer, encoded)

# Compile the autoencoder
autoencoder.compile(optimizer='adam', loss='mse')

# Train the autoencoder
autoencoder.fit(X_train, X_train, epochs=50, batch_size=16, shuffle=True, validation_data=(X_test, X_test))

# Get the reduced representation of the data
X_train_encoded = encoder.predict(X_train)
X_test_encoded = encoder.predict(X_test)

# Visualization
plt.figure(figsize=(8, 6))
scatter = plt.scatter(X_train_encoded[:, 0], X_train_encoded[:, 1], c=y_train, cmap='viridis')
plt.colorbar(scatter, ticks=[0, 1, 2])
plt.xlabel('Encoded Dimension 1')
plt.ylabel('Encoded Dimension 2')
plt.title('2D Visualization of Encoded Iris Data')
plt.show()

data.shape

import numpy as np
import tensorflow as tf
from tensorflow.keras.layers import Input, Dense
from tensorflow.keras.models import Model
from sklearn.datasets import load_iris
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt

# Load and prepare the Iris dataset
iris = load_iris()
data = iris.data
labels = iris.target

# Standardize the data
scaler = StandardScaler()
data = scaler.fit_transform(data)

# Split into train and test sets
X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.3, random_state=42)

# Define the autoencoder model
input_dim = X_train.shape[1]
encoding_dim = 2  # Reduce to 2 dimensions for visualization

# Input layer
input_layer = Input(shape=(input_dim,))

# Hidden layer (additional layer for more complexity)
hidden_layer = Dense(8, activation='relu')(input_layer)

# Encoding layer
encoded = Dense(encoding_dim, activation='relu')(hidden_layer)

# Decoding layer
decoded_hidden = Dense(8, activation='relu')(encoded)
decoded = Dense(input_dim, activation='sigmoid')(decoded_hidden)

# Autoencoder model
autoencoder = Model(input_layer, decoded)

# Encoder model to extract the reduced representation
encoder = Model(input_layer, encoded)

# Compile the autoencoder
autoencoder.compile(optimizer='adam', loss='mse')

# Train the autoencoder
autoencoder.fit(X_train, X_train, epochs=100, batch_size=16, shuffle=True, validation_data=(X_test, X_test))

# Get the reduced representation of the data
X_train_encoded = encoder.predict(X_train)
X_test_encoded = encoder.predict(X_test)

# Visualization
plt.figure(figsize=(8, 6))
scatter = plt.scatter(X_train_encoded[:, 0], X_train_encoded[:, 1], c=y_train, cmap='viridis')
plt.colorbar(scatter, ticks=[0, 1, 2])
plt.xlabel('Encoded Dimension 1')
plt.ylabel('Encoded Dimension 2')
plt.title('2D Visualization of Encoded Iris Data with Enhanced Autoencoder')
plt.show()

